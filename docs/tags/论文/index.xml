<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>论文 on Tan Jay | 唐 洁</title>
    <link>/tags/%E8%AE%BA%E6%96%87/</link>
    <description>Recent content in 论文 on Tan Jay | 唐 洁</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 17 Oct 2022 00:00:00 +0000</lastBuildDate>
    <atom:link href="/tags/%E8%AE%BA%E6%96%87/" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>高维可尝试方向</title>
      <link>/cn/2022/10/17/higdim/</link>
      <pubDate>Mon, 17 Oct 2022 00:00:00 +0000</pubDate>
      <author>Tan Jay</author>
      <guid>/cn/2022/10/17/higdim/</guid>
      <description>
        <![CDATA[
        <h2 id="高维问题">高维问题</h2>
<ol>
<li>传统的数据处理方法在处理高维数据时不能满足稳健性要求；</li>
<li>高维导致空间的样本数变少，从而使得一些统计上的渐近性难以实现；</li>
<li>维数的增加亦会导致数据的计算量迅速上升。</li>
</ol>
<h2 id="方向">方向</h2>
<h3 id="方向一">方向一</h3>
<p>根据 <strong>石坚</strong><a href="/papers/HigDimen/2.pdf">《高维线性模型中的经验似然》</a>思想，说明高维空间模型中，在适当的正则条件下，可对经验似然比统计量进行修正，并且修正后的经验似然比统计量服从标准正态分布。</p>
<p>实际进展<a href="https://tang-jay.github.io/HighDimen">见此</a>。</p>
<h3 id="方向二">方向二</h3>
<p>当 <code>$\beta$</code> 有很多分量为零，可以做变量选择，比如Lasso、惩罚经验似然，先选出非零的分量，然后对被选出来的非零分量做统计推断。</p>
<h3 id="方向三">方向三</h3>
<p>当 <code>$\beta$</code> 有很多分量不为零，简单地考虑变量选择是不够的，根据 <strong>曾力立</strong><a href="/papers/HigDimen/4.caj">《高维线性回归模型下的经验似然》</a>思想，说明高维空间模型中可以建立简单经验似然统计量，并且证明该统计量服从 <code>$\chi^2_1$</code>，从模拟的角度说明，犯两类错误的概率令人满意，且大大节省了计算成本。</p>

        
        ]]>
      </description>
    </item>
    
    
    
    <item>
      <title>高维文献摘录</title>
      <link>/cn/2022/10/16/higdim/</link>
      <pubDate>Sun, 16 Oct 2022 00:00:00 +0000</pubDate>
      <author>Tan Jay</author>
      <guid>/cn/2022/10/16/higdim/</guid>
      <description>
        <![CDATA[
        <!-- 
- [``](/papers/HigDimen/4.caj)
> 
-->
<h2 id="奠基">奠基</h2>
<ul>
<li>石坚  <a href="/papers/HigDimen/2.pdf"><code>高维线性模型中的经验似然</code></a></li>
</ul>
<blockquote>
<p>当协变量的维数随样本量增加时，常规的经验似然推断失效，在适当的正则条件下，对修正的经验似然比统计量给出了渐近分布理论。</p>
</blockquote>
<blockquote>
<p>曾力立提到，该论文表明，当协变量维数以某种合理的速度趋于无穷大时，我们仍可以利用经验似然方法构造 <code>$\beta$</code> 的置信域，不过此时有关临界值的确定依赖于正态分布而非卡方分布。</p>
</blockquote>
<ul>
<li>陈松溪 <a href="https://xueshu.zidianzhan.net/citations?user=b3XlCawAAAAJ&amp;hl=zh-CN&amp;oi=sra">彭亮</a> <a href="/papers/HigDimen/3.pdf"><code>高维对经验似然的影响</code></a></li>
</ul>
<blockquote>
<p>在一般的多元模型下，该文评估了数据维数对高维数据经验似然比的渐近正态性的影响，指出多元随机向量各分量之间的数据维数和相关性直接通过协方差矩阵的迹和特征值来影响经验似然。</p>
</blockquote>
<blockquote>
<p>曾力立提到，该文在多元模型下研究了均值的渐近性质。</p>
</blockquote>
<blockquote>
<p>毛沥悦提到，该文证明了当参数的维数变化时，经验似然方法仍然有效。</p>
</blockquote>
<ul>
<li>陈松溪 <a href="https://xs2.zidianzhan.net/citations?user=lZUH1lcAAAAJ&amp;hl=zh-CN&amp;oi=sra">汤琤咏</a> <a href="/papers/HigDimen/3-1.pdf"><code>高维经验似然推断</code></a></li>
</ul>
<blockquote>
<p>研究两个问题，多元参数估计量的置信域和模型假设检验，并提出两个建议，新的估计方程和检验统计量。</p>
</blockquote>
<ul>
<li><a href="https://xueshu.zidianzhan.net/citations?user=pGvWCH4AAAAJ&amp;hl=zh-CN&amp;oi=sra">Hjort N L</a> <a href="/papers/HigDimen/1-1.pdf"><code>拓展经验似然应用范围</code></a></li>
</ul>
<blockquote>
<p>曾力立提到，该文在基于plug-in估计对经验似然方法做了一个推广研究。</p>
</blockquote>
<ul>
<li><a href="https://xs2.zidianzhan.net/citations?user=lZUH1lcAAAAJ&amp;hl=zh-CN&amp;oi=sra">汤琤咏</a> <a href="/papers/HigDimen/5.pdf"><code>高维惩罚经验似然</code></a></li>
</ul>
<blockquote>
<p>曾力立提到，该文将经验似然应用于高维变量选择。</p>
</blockquote>
<blockquote>
<p>何帮强提到，该文首次提出的惩罚经验似然（PEL）被用于分析多变量的均值向量和线性模型的发散数量回归系数。该文证实的PEL具有优点在来自非参数似然法的效率和适应性方面。另外，PEL方法具有使用数据来确定置信区域的形状和取向，与EL有相同优点并且不估计共协方差。</p>
</blockquote>
<ul>
<li><a href="https://xs2.zidianzhan.net/citations?user=rsT2stMAAAAJ&amp;hl=zh-CN&amp;oi=sra">冷琛雷</a> <a href="/papers/HigDimen/8.pdf"><code>惩罚经验似然与高维估计方程</code></a></li>
</ul>
<blockquote>
<p>何帮强提到，该文将PEL方法应用于一般估计方程的参数估计和变量选择，并显示PEL具有oracle特征。</p>
</blockquote>
<h2 id="经验似然">经验似然</h2>
<ul>
<li>曾力立 <a href="/papers/HigDimen/4.caj"><code>高维线性回归模型下的经验似然</code></a></li>
</ul>
<blockquote>
<p>许多经典的低维数据处理方法，在处理髙维数据时面临着难以解决的困难。例如，传统的数据处理方法在处理高维数据时不能满足稳健性要求；高维导致空间的样本数变少，从而使得一些统计上的渐近性难以实现；维数的增加亦会导致数据的计算量迅速上升。</p>
</blockquote>
<blockquote>
<p>在这篇论文里，作者的主要目的是检验一个可能的高维线性回归模型的系数是否等于一个给定值。创新点：</p>
<ol>
<li>将传统经验似然方法里面的高维约束条件巧妙地变换成与维数无关的低维情形，以此构造出新的约束条件，再利用经验似然的方法解决相关问题。</li>
<li>在一般经验似然方法里加入了伪观测值，从而作出了一个新奇的调整。调整后的经验似然方法保留了之前方法的所有最优性准则．不仅如此，该方法下的区间覆盖率更接近于置信水平，而且还不需要Bartlett校正和Bootstrap方法里那么复杂的程序。</li>
<li>针对不同的维数，有区别地加入了约束条件的个数，一方面使得犯两类错误的概率令人满意，另一方面也大大地节省了计算成本。</li>
</ol>
</blockquote>
<blockquote>
<p>曾力立指出，线性模型的统计推断中 <code>$p$</code> 是 <code>$n$</code> 的指数阶的情况下的研究现状：</p>
<ol>
<li><code>$\beta$</code> 有很多分量为零，首先选出非零的分量（即变量选择，如Lasso），然后对被选出来的非零分量做统计推断。</li>
<li><code>$\beta$</code> 有很多分量不为零，简单地考虑变量选择是不够的，需要新的方法，借鉴<a href="https://xueshu.zidianzhan.net/citations?user=b3XlCawAAAAJ&amp;hl=zh-CN&amp;oi=sra">彭亮</a>在 <a href="/papers/HigDimen/7.pdf"><em>Empirical likelihood test for high dimensional linear models</em></a> 一文中的思想，通过一定手段——将样本数据分为两个部分，用每两个旧的观测值构造一个新的观测值——将约束条件与维数无关。</li>
</ol>
</blockquote>
<blockquote>
<p>该文思路：利用已有的观测值去构造 <code>$\omega_i(\beta)$</code>，构造出来的 <code>$\omega_i(\beta)$</code>需满足</p>
<ol>
<li><code>$E\omega_i(\beta_0)=0$</code>；</li>
<li><code>$E\omega_i(\beta_0)=0$</code> 非常接近于<code>$L_1$</code>范数。</li>
</ol>
</blockquote>
<blockquote>
<p>由此将经验似然的方法应用于估计式及 <code>$E\omega_i(\beta_0)=0$</code>，从而解决 <code>$\beta$</code> 有很多分量不为零的假设检验问题。曾力立将高维转换为一维进行考虑，并称其为简单经验似然。</p>
</blockquote>
<ul>
<li>何帮强 <a href="/papers/HigDimen/5.caj"><code>半参数带固定效应的面板数据模型的经验似然</code></a></li>
</ul>
<blockquote>
<p>第四章，对于带固定效应面板数据的高维部分线性误差变量模型，当误差方差为己知和未知情形下。在这一章，作者建议一个修正的回归参数和最大经验似然比率回归参数。同时，依据惩罚经验似然方法，这个模型的参数估计和变量选择被调查，这个建议的惩罚经验似然被证明具有神特征。同时，作者建议的惩罚经验似然比率统计在原假设下具有渐近卡方分布，其结果可以用来构造未知参数的置信域。模拟和实证结果用来评估经验似然方法的性能。</p>
</blockquote>
<ul>
<li>方江林 <a href="/papers/HigDimen/11.caj"><code>维数发散的高维数据的经验似然</code></a></li>
</ul>
<blockquote>
</blockquote>
<ul>
<li>马昀蓓 <a href="/papers/HigDimen/12.caj"><code>相依误差下线性模型的经验似然</code></a></li>
</ul>
<blockquote>
</blockquote>
<ul>
<li>白璐 <a href="/papers/HigDimen/4.pdf"><code>固定和自适应设计下高维广义线性模型的经验似然检验</code></a></li>
</ul>
<blockquote>
</blockquote>
<ul>
<li>曾云辉 <a href="/papers/HigDimen/7.caj"><code>高维线性模型和部分线性模型的相合统计推断</code></a></li>
</ul>
<blockquote>
</blockquote>
<h2 id="惩罚经验似然">惩罚经验似然</h2>
<ul>
<li>毛沥悦 <a href="/papers/HigDimen/2.caj"><code>部分线性模型和广义线性模型的惩罚经验似然</code></a></li>
</ul>
<blockquote>
<p>第三章讨论高维情况下广义线性模型的参数估计与变量选择问题，通过通过适当的辅助随机变量研究了自适应Lasso下高维广义线性模型的惩罚经验似然。主要的结论有提出的方法具有Oracle性质以及在假设检验中构造的检验统计量的渐近分布为卡方分布。</p>
</blockquote>
<ul>
<li>文怡方 <a href="/papers/HigDimen/9.caj"><code>部分函数型线性模型的高维惩罚经验似然</code></a></li>
</ul>
<blockquote>
</blockquote>
<ul>
<li>吕升日 <a href="/papers/HigDimen/1.caj"><code>高维半参数回归模型的惩罚经验似然</code></a></li>
</ul>
<blockquote>
<p>在半参数回归模型中，当协变量的维度随着样本量的增大而增大，即当协变量维度较高时，将会遇到“维数祸根”等问题。将经验似然方法与惩罚函数相结合并应用于模型当中，可以有效的解决高维数据情况下的变量选择问题，从而降低模型的复杂度，解决模型在做预测时的不稳定性的问题。</p>
</blockquote>
<ul>
<li>李吉妮 <a href="/papers/HigDimen/3.caj"><code>单指标模型的高维惩罚经验似然</code></a></li>
</ul>
<blockquote>
<p>高维数据的变量选择问题。在处理高维数据时，单指标模型的降维特性有效地避免了“维数灾难问题，还抓住了高维数据的稀疏特性。在论文中考虑参数维数会随着样本容量的增大而同时增大的情形，对单指标模型提出了一种稳健的变量选择方法：基于SCAD惩罚函数及经验似然的惩罚经验似然。</p>
</blockquote>
<blockquote>
<p>论文发现，在一定正则条件下，参数维数随样本量同时增大的惩罚经验似然估计仍具有Oracle性质，即如果已知真实模型是稀疏的模型，则以概率趋向于1，惩罚经验似然确定模型的非零参数估计具有稀疏性（惩罚似然估计值应该有一个限制，这个限制自动将那些较小的估计系数设为，进而去掉，并删除对应的变量，从而降低模型的复杂度）。</p>
</blockquote>
<ul>
<li>刘琦 <a href="/papers/HigDimen/8.caj"><code>广义线性模型的高维惩罚经验似然</code></a></li>
</ul>
<blockquote>
</blockquote>
<h2 id="变量选择">变量选择</h2>
<ul>
<li><a href="https://xs2.zidianzhan.net/citations?user=sdw9roIAAAAJ&amp;hl=zh-CN&amp;oi=sra">Meinshausen N</a> <a href="/papers/HigDimen/6.pdf"><code>高维回归p值</code></a></li>
</ul>
<blockquote>
<p>曾力立提到，该文研究了高维线性回归模型中的变量选择问题。</p>
</blockquote>
<ul>
<li>李玲玲 <a href="/papers/HigDimen/6.caj"><code>高维线性模型的变量选择</code></a></li>
</ul>
<blockquote>
</blockquote>
<ul>
<li>唐莹莹 <a href="/papers/HigDimen/10.caj"><code>两类空间面板数据模型的变量选择</code></a></li>
</ul>
<blockquote>
</blockquote>

        
        ]]>
      </description>
    </item>
    
    
    
    <item>
      <title>在读论文</title>
      <link>/cn/2022/09/23/paper/</link>
      <pubDate>Fri, 23 Sep 2022 00:00:00 +0000</pubDate>
      <author>Tan Jay</author>
      <guid>/cn/2022/09/23/paper/</guid>
      <description>
        <![CDATA[
        <!-- <font style="background-color: #FFFFCD;">[`PDF`](/papers/HigDimen/2.pdf)</font>
<font style="background-color: #F0FFFF;">[`NOTE`](/papers/HigDimen/2-note.pdf)</font>
<font style="background-color: #E6E6FA;">[](/papers/HigDimen/2-code.pdf)</font>
-->
<h2 id="高维数据-https-tang-jay-github-io-highdimen"><a href="https://tang-jay.github.io/HighDimen">高维数据</a></h2>
<ul>
<li>
<p>Nordmana, D.J. and Lahiri, S.N. (2014). A review of empirical likelihood methods for time series. <em>Journal of Statistical Planning and Inference, 155</em>, 1-18.
<a href="/papers/HigDimen/1.pdf"><code>PDF</code></a>
<a href="/papers/HigDimen/1-note.pdf"><code>NOTE</code></a></p>
</li>
<li>
<p>Shi, J. (2007). Empirical likelihood for higher dimensional linear models. <em>J. Sys. Sci. &amp; Math. Scis., 27</em>, 124-133.
<a href="/papers/HigDimen/2.pdf"><code>PDF</code></a>
<a href="/papers/HigDimen/2-note.pdf"><code>NOTE</code></a></p>
<ul>
<li><a href="/papers/HigDimen/2-1.pdf">1984 Ghosh M</a></li>
<li><a href="/papers/HigDimen/2-2.pdf">2000 Shi J</a></li>
<li><a href="/papers/HigDimen/2-3.pdf">1987 de Jong P</a></li>
</ul>
</li>
<li>
<p>Chen, S.X., Peng, L. and Qin, Y.L. (2009). Effects of data dimension on empirical likelihood. <em>Biometrika, 96</em>, 711-722.
<a href="/papers/HigDimen/3.pdf"><code>PDF</code></a>
<a href="/papers/HigDimen/3-note.pdf"><code>NOTE</code></a>
<a href="https://github.com/Tang-Jay/HigDimen/tree/main/2009ChenSongxi"><code>CODE</code></a></p>
</li>
<li>
<p>Chang, J.Y., Chen, S.X. and Tang, C.Y. (2020). High-dimensional empirical likelihood inference. <em>Biometrika, 00</em>, 1-21.
<a href="/papers/HigDimen/3-1.pdf"><code>PDF</code></a></p>
</li>
<li>
<p>Chang, J.Y., Chen, S.X. and Chen, X.H. (2015). High dimensional generalized empirical likelihood for moment restrictions with dependent data. <em>Journal of Econometrics,  185</em>, 283-304.
<a href="/papers/HigDimen/3-2.pdf"><code>PDF</code></a></p>
</li>
<li>
<p>N.L. Hjort, I.W. Mckeague, I.V. Keilegom, 2009. Extending the scop of empirical likelihood. <em>The Annals of Statistics. 37</em>, 1079-1111. <a href="/papers/HigDimen/1-1.pdf"><code>PDF</code></a></p>
</li>
</ul>

        
        ]]>
      </description>
    </item>
    
    
    
    <item>
      <title>对称矩阵</title>
      <link>/cn/2022/09/22/paper/</link>
      <pubDate>Thu, 22 Sep 2022 00:00:00 +0000</pubDate>
      <author>Tan Jay</author>
      <guid>/cn/2022/09/22/paper/</guid>
      <description>
        <![CDATA[
        <blockquote>
<p>Hessian矩阵、协方差矩阵、空间权重矩阵都是对称矩阵，相关的性质有必要了解一下。</p>
</blockquote>
<hr>
<h3 id="对称矩阵">对称矩阵</h3>
<ol>
<li><a href="https://mp.weixin.qq.com/s/mTiT8wNovGGAawlO-608_w">矩阵二次型及其性质</a></li>
<li><a href="/papers/SymMatrix/%E5%AF%B9%E7%A7%B0%E7%9F%A9%E9%98%B5%E7%9A%84%E4%B8%80%E4%BA%9B%E6%80%A7%E8%B4%A8%E5%92%8C%E5%AE%9A%E7%90%86_%E9%9F%A9%E6%8C%AF%E8%8A%B3.pdf">对称矩阵的一些性质和定理_韩振芳.pdf</a></li>
<li><a href="/papers/SymMatrix/%E5%AF%B9%E7%A7%B0%E7%9F%A9%E9%98%B5%E7%9A%84%E6%80%A7%E8%B4%A8%E5%8F%8A%E5%BA%94%E7%94%A8_%E5%8F%B8%E5%87%A4%E5%A8%9F.pdf">对称矩阵的性质及应用_司凤娟.pdf</a></li>
<li><a href="/papers/SymMatrix/%E5%AF%B9%E7%A7%B0%E7%9F%A9%E9%98%B5%E6%95%99%E4%B8%8E%E5%AD%A6_%E7%8E%8B%E5%AE%8F%E5%85%B4.pdf">对称矩阵教与学_王宏兴.pdf</a></li>
</ol>
<h3 id="反对称矩阵">反对称矩阵</h3>
<ol>
<li><a href="/papers/SymMatrix/%E5%AF%B9%E7%A7%B0%E7%9F%A9%E9%98%B5%E4%B8%8E%E5%8F%8D%E5%AF%B9%E7%A7%B0%E7%9F%A9%E9%98%B5%E7%9A%84%E8%8B%A5%E5%B9%B2%E6%80%A7%E8%B4%A8_%E6%AD%A6%E7%A7%80%E7%BE%8E.pdf">对称矩阵与反对称矩阵的若干性质_武秀美.pdf</a></li>
<li><a href="/papers/SymMatrix/%E5%AF%B9%E7%A7%B0%E7%9F%A9%E9%98%B5%E5%92%8C%E5%8F%8D%E5%AF%B9%E7%A7%B0%E7%9F%A9%E9%98%B5%E7%9A%84%E8%8B%A5%E5%B9%B2%E6%80%A7%E8%B4%A8_%E9%82%B9%E6%9C%AC%E5%BC%BA.pdf">对称矩阵和反对称矩阵的若干性质_邹本强.pdf</a></li>
<li><a href="/papers/SymMatrix/%E5%85%B3%E4%BA%8E%E5%AF%B9%E7%A7%B0%E7%9F%A9%E9%98%B5%E4%B8%8E%E5%8F%8D%E5%AF%B9%E7%A7%B0%E7%9F%A9%E9%98%B5%E7%9A%84%E8%8B%A5%E5%B9%B2%E6%80%A7%E8%B4%A8_%E6%9C%B1%E4%BA%9A%E8%8C%B9.pdf">关于对称矩阵与反对称矩阵的若干性质_朱亚茹.pdf</a></li>
</ol>
<h3 id="非对称矩阵">非对称矩阵</h3>
<ol>
<li><a href="/papers/SymMatrix/%E9%9D%9E%E5%AF%B9%E7%A7%B0%E6%AD%A3%E5%AE%9A%E7%9F%A9%E9%98%B5%E7%9A%84%E6%80%A7%E8%B4%A8_%E7%8E%8B%E4%B8%96%E6%81%92.pdf">非对称正定矩阵的性质_王世恒.pdf</a></li>
</ol>
<h3 id="对称矩阵应用">对称矩阵应用</h3>
<ol>
<li><a href="/papers/SymMatrix/%E5%AE%9E%E5%AF%B9%E7%A7%B0%E7%9F%A9%E9%98%B5%E7%9A%84%E6%80%A7%E8%B4%A8%E5%8F%8A%E5%85%B6%E5%BA%94%E7%94%A8_%E8%96%9B%E5%BB%BA%E6%98%8E.pdf">实对称矩阵的性质及其应用_薛建明.pdf</a></li>
<li><a href="/papers/SymMatrix/%E5%AE%9E%E5%AF%B9%E7%A7%B0%E7%9F%A9%E9%98%B5%E7%89%B9%E5%BE%81%E5%80%BC%E7%9A%84%E6%80%A7%E8%B4%A8%E5%8F%8A%E5%85%B6%E5%BA%94%E7%94%A8_%E6%9D%A8%E5%8F%AC.pdf">实对称矩阵特征值的性质及其应用_杨召.pdf</a></li>
</ol>
<h3 id="特征向量求法">特征向量求法</h3>
<ol>
<li><a href="/papers/SymMatrix/%E8%AE%A1%E7%AE%97%E5%AE%9E%E5%AF%B9%E7%A7%B0%E7%9F%A9%E9%98%B5%E7%89%B9%E5%BE%81%E5%80%BC%E7%89%B9%E5%BE%81%E5%90%91%E9%87%8F%E7%9A%84%E5%B9%82%E6%B3%95_%E6%9B%BE%E8%8E%89.pdf">计算实对称矩阵特征值特征向量的幂法_曾莉.pdf</a></li>
<li><a href="/papers/SymMatrix/%E5%88%A9%E7%94%A8%E7%89%B9%E5%BE%81%E7%9F%A9%E9%98%B5%E6%B1%82%E5%AE%9E%E5%AF%B9%E7%A7%B0%E7%9F%A9%E9%98%B5%E7%9A%84%E7%89%B9%E5%BE%81%E5%90%91%E9%87%8F_%E5%AD%9F%E5%AE%AA%E8%90%8C.pdf">利用特征矩阵求实对称矩阵的特征向量_孟宪萌.pdf</a></li>
</ol>
<h3 id="其他特殊矩阵">其他特殊矩阵</h3>
<ol>
<li><a href="https://mp.weixin.qq.com/s/Ci8iJ1YK3-AV8xWbGMJwrw">幂等矩阵、投影矩阵和Cochran定理</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzI3NzE3NDAxMg==&amp;mid=2247490095&amp;idx=1&amp;sn=16bc42b1823fc8067270b2a4428600f0&amp;chksm=eb6b19bcdc1c90aacb507441d5b4e4fb8a72ef1ffb4f2f161c44549aad063f11ccfaef076842&amp;scene=178&amp;cur_album_id=2185022661871960071#rd">Cochran定理</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzI3NzE3NDAxMg==&amp;mid=2247484817&amp;idx=1&amp;sn=74dc04683a2da5b0282be80f0e0505dc&amp;chksm=eb6b0602dc1c8f1447ec134259af88d42f2b67c10a3fde0026d4dbf594fb7955b4420bbbfd1a&amp;cur_album_id=2185022661871960071&amp;scene=190#rd">分块矩阵及其统计学应用</a></li>
</ol>

        
        ]]>
      </description>
    </item>
    
    
    
    <item>
      <title>推荐论文</title>
      <link>/cn/2022/09/21/paper/</link>
      <pubDate>Wed, 21 Sep 2022 00:00:00 +0000</pubDate>
      <author>Tan Jay</author>
      <guid>/cn/2022/09/21/paper/</guid>
      <description>
        <![CDATA[
        <h2 id="空间数据">空间数据</h2>
<ul>
<li>
<p><input disabled="" type="checkbox"> Baltagi, B. H., Song, S. H., and Won K. (2003). Testing panel data regression models with spatial error correlation. <em>Journal of Econometrics, 117</em>, 123-150. <a href="/papers/QinRecom/Reading_1.pdf"><code>PDF</code></a></p>
</li>
<li>
<p><input disabled="" type="checkbox"> Baltagi, B. H. (2021). <em>Econometric Analysis of Panel Data</em>. Springer Cham. <a href="/papers/QinRecom/Reading_2.pdf"><code>PDF</code></a></p>
</li>
</ul>

        
        ]]>
      </description>
    </item>
    
    
    
    <item>
      <title>摘要写作</title>
      <link>/cn/2022/09/20/abstract/</link>
      <pubDate>Tue, 20 Sep 2022 00:00:00 +0000</pubDate>
      <author>Tan Jay</author>
      <guid>/cn/2022/09/20/abstract/</guid>
      <description>
        <![CDATA[
        <h3 id="摘要笔记">摘要笔记</h3>
<ul>
<li>
<p><a href="/papers/QinRecom/essay_1.pdf">NOTE 1</a></p>
</li>
<li>
<p><a href="/papers/QinRecom/essay_2.pdf">NOTE 2</a></p>
</li>
</ul>

        
        ]]>
      </description>
    </item>
    
    
  </channel>
</rss>
