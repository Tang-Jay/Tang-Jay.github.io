<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>论文 on Tan Jay | 唐 洁</title>
    <link>/tags/%E8%AE%BA%E6%96%87/</link>
    <description>Recent content in 论文 on Tan Jay | 唐 洁</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 21 Oct 2022 00:00:00 +0000</lastBuildDate>
    <atom:link href="/tags/%E8%AE%BA%E6%96%87/" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>空间文献摘录</title>
      <link>/cn/2022/10/21/space/</link>
      <pubDate>Fri, 21 Oct 2022 00:00:00 +0000</pubDate>
      <author>Tan Jay</author>
      <guid>/cn/2022/10/21/space/</guid>
      <description>
        <![CDATA[
        <h2 id="空间模型">空间模型</h2>
<h3 id="秦永松-https-xueshu-zidianzhan-net-scholar-hl-zh-cn-as-sdt-0-2c5-q-ys-qin-empirical-likelihood-btng"><a href="https://xueshu.zidianzhan.net/scholar?hl=zh-CN&amp;as_sdt=0%2C5&amp;q=YS+Qin+empirical+likelihood&amp;btnG=">秦永松</a></h3>
<p><a href="/papers/QinRecom/Qin-2.pdf"><code>空间计量经济模型的经验似然研究进展</code></a></p>
<blockquote>
<p>这是一篇经验似然方法应用于空间模型的综述。</p>
</blockquote>
<p><a href="/papers/SpaModel/Qin-1.pdf"><code>含空间误差项的空间自回归模型的经验似然</code></a></p>

        
        ]]>
      </description>
    </item>
    
    
    
    <item>
      <title>面板文献摘录</title>
      <link>/cn/2022/10/20/panel/</link>
      <pubDate>Thu, 20 Oct 2022 00:00:00 +0000</pubDate>
      <author>Tan Jay</author>
      <guid>/cn/2022/10/20/panel/</guid>
      <description>
        <![CDATA[
        <h2 id="面板数据-https-xs2-zidianzhan-net-scholar-hl-zh-cn-as-sdt-0-2c5-q-panel-data-btng"><a href="https://xs2.zidianzhan.net/scholar?hl=zh-CN&amp;as_sdt=0%2C5&amp;q=panel+data&amp;btnG=">面板数据</a></h2>
<h3 id="何帮强-https-kns-cnki-net-kcms-detail-knetsearch-aspx-dbcode-cjfd-code-000021434404-sfield-au-skey-何帮强-uniplatform-nzkpt"><a href="https://kns.cnki.net/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;code=000021434404&amp;sfield=au&amp;skey=%E4%BD%95%E5%B8%AE%E5%BC%BA&amp;uniplatform=NZKPT">何帮强</a></h3>
<p><a href="/papers/HigDimen/%E4%BD%95%E5%B8%AE%E5%BC%BA.caj"><code>带固定效应 + 面板数据 + 半参数模型 + 经验似然</code></a></p>
<blockquote>
<p>此篇博士论文中研究了，带固定效应面板数据半参数模型的经验似然问题。</p>
</blockquote>
<p><a href="/papers/PanEmpir/HeBQ-2.pdf"><code>带固定效应 + 面板数据 + 部分线性模型 + 块经验似然</code></a></p>
<p><a href="/papers/PanEmpir/HeBQ-4.pdf"><code>带固定效应 + 面板数据 + 部分线性误差变量模型 + 统计推断</code></a></p>
<p><a href="/papers/PanEmpir/HeBQ-5.pdf"><code>带固定效应 + 面板数据 + 部分线性误差变量模型 + 惩罚经验似然</code></a></p>
<p><a href="/papers/PanEmpir/HeBQ-1.pdf"><code>带固定效应 + 面板数据 + 半变系数模型 + 经验似然</code></a></p>
<p><a href="/papers/PanEmpir/HeBQ-7.pdf"><code>鞅差序列 + 非线性半参数测量误差模型 + 经验似然</code></a></p>
<p><a href="/papers/PanEmpir/HeBQ-6.pdf"><code>删失数据 + 面板数据 + 半变系数变量误差模型 + 经验似然</code></a></p>
<h3 id="李高荣-https-xueshu-zidianzhan-net-citations-user-cakqlosaaaaj-hl-zh-cn-oi-sra"><a href="https://xueshu.zidianzhan.net/citations?user=cakQLOsAAAAJ&amp;hl=zh-CN&amp;oi=sra">李高荣</a></h3>
<p><a href="/papers/HigDimen/%E4%BD%95%E5%B8%AE%E5%BC%BA.caj"><code>带固定效应 + 面板数据 + 部分线性模型 + 经验似然</code></a></p>
<p><a href="/papers/HigDimen/9.pdf"><code>高维变系数 + 部分线性模型 + 经验似然</code></a></p>
<blockquote>
<p>方江林提到，该文提出了改进的经验似然方法可以提高其统计推断的效率。</p>
</blockquote>
<!--
[`Monotone empirical bayes test for the parameter of pareto distribution under random censorship
`](/papers/PanEmpir/HeBQ-3.pdf)

> 题外话，一不留神，开学两个月了，啥也没弄出来，顿挫感一下子就上来了。这学期还计划写一篇有意义的论文呢，现在看来，长路漫漫了。一方面呢，要保持顿挫感，它督促我珍惜时间继续努力，另一方面，不能让顿挫感泛滥，这会让我陷入无限的自责。
-->
        
        ]]>
      </description>
    </item>
    
    
    
    <item>
      <title>高维可尝试方向</title>
      <link>/cn/2022/10/17/higdim/</link>
      <pubDate>Mon, 17 Oct 2022 00:00:00 +0000</pubDate>
      <author>Tan Jay</author>
      <guid>/cn/2022/10/17/higdim/</guid>
      <description>
        <![CDATA[
        <h2 id="高维问题">高维问题</h2>
<p>曾力立说，</p>
<ol>
<li>传统的数据处理方法在处理高维数据时不能满足稳健性要求；</li>
<li>高维导致空间的样本数变少，从而使得一些统计上的渐近性难以实现；</li>
<li>维数的增加亦会导致数据的计算量迅速上升。</li>
</ol>
<p>方江林说，</p>
<ol>
<li>维数的增大会导致“维数灾难”问题；</li>
<li>经典大样本统计推断理论一般都是建立在维数固定且相对较小，而样本量趋于无穷的假设下，在数据维数p随着样本容量n一起趋向无穷时，特别是在“超高维”(p &gt; n)数据情形下，经典统计理论的结论可能不再有效。</li>
</ol>
<h2 id="方向">方向</h2>
<h3 id="方向一">方向一</h3>
<p>根据 <strong>石坚</strong><a href="/papers/HigDimen/2.pdf">《高维线性模型中的经验似然》</a>思想，说明高维空间模型中，在适当的正则条件下，可对经验似然比统计量进行修正，并且修正后的经验似然比统计量服从标准正态分布。</p>
<p>实际进展<a href="https://tang-jay.github.io/HighDimen">见此</a>。</p>
<h3 id="方向二">方向二</h3>
<p>当 <code>$\beta$</code> 有很多分量为零，可以做变量选择，比如Lasso、惩罚经验似然，先选出非零的分量，然后对被选出来的非零分量做统计推断。</p>
<h3 id="方向三">方向三</h3>
<p>当 <code>$\beta$</code> 有很多分量不为零，简单地考虑变量选择是不够的，根据 <strong>曾力立</strong><a href="/papers/HigDimen/4.caj">《高维线性回归模型下的经验似然》</a>思想，说明高维空间模型中可以建立简单经验似然统计量，并且证明该统计量服从 <code>$\chi^2_1$</code>，从模拟的角度说明，犯两类错误的概率令人满意，且大大节省了计算成本。</p>

        
        ]]>
      </description>
    </item>
    
    
    
    <item>
      <title>高维文献摘录</title>
      <link>/cn/2022/10/16/higdim/</link>
      <pubDate>Sun, 16 Oct 2022 00:00:00 +0000</pubDate>
      <author>Tan Jay</author>
      <guid>/cn/2022/10/16/higdim/</guid>
      <description>
        <![CDATA[
        <!-- 
- [``](/papers/HigDimen/曾力立.caj)
> 
-->
<h2 id="奠基">奠基</h2>
<ul>
<li>石坚. <a href="/papers/HigDimen/2.pdf"><code>高维线性模型中的经验似然</code></a></li>
</ul>
<blockquote>
<p>当协变量的维数随样本量增加时，常规的经验似然推断失效，在适当的正则条件下，对修正的经验似然比统计量给出了渐近分布理论。</p>
</blockquote>
<blockquote>
<p>曾力立提到，该论文表明，当协变量维数以某种合理的速度趋于无穷大时，我们仍可以利用经验似然方法构造 <code>$\beta$</code> 的置信域，不过此时有关临界值的确定依赖于正态分布而非卡方分布。</p>
</blockquote>
<ul>
<li><a href="https://xueshu.zidianzhan.net/citations?user=pGvWCH4AAAAJ&amp;hl=zh-CN&amp;oi=sra">Hjort et al.</a> <a href="/papers/HigDimen/1-1.pdf"><code>拓展经验似然应用范围</code></a></li>
</ul>
<blockquote>
<p>方江林提到，当 <code>$p=o_p(n^{1/3}) \to \infty$</code> 时，在一定条件下，该文得出了经验似然比统计量渐近分布为正态分布的结论。</p>
</blockquote>
<blockquote>
<p>曾力立提到，该文在基于plug-in估计对经验似然方法做了一个推广研究。</p>
</blockquote>
<ul>
<li>陈松溪，<a href="https://xueshu.zidianzhan.net/citations?user=b3XlCawAAAAJ&amp;hl=zh-CN&amp;oi=sra">彭亮</a>. <a href="/papers/HigDimen/3.pdf"><code>数据维数对经验似然的影响</code></a></li>
</ul>
<blockquote>
<p>在一般的多元模型下，该文评估了数据维数对高维数据经验似然比的渐近正态性的影响，指出多元随机向量各分量之间的数据维数和相关性直接通过协方差矩阵的迹和特征值来影响经验似然。</p>
</blockquote>
<blockquote>
<p>方江林提到，该文是在Hjort基础上，进一步研究了样本维数对经验似然方法的影响，证明了当 <code>$p=o_p(n^{1/2}) \to \infty$</code> 时，经验似然方法仍然适用，改进了Hjort的结果。</p>
</blockquote>
<blockquote>
<p>曾力立提到，该文在多元模型下研究了均值的渐近性质。</p>
</blockquote>
<blockquote>
<p>毛沥悦提到，该文证明了当参数的维数变化时，经验似然方法仍然有效。</p>
</blockquote>
<ul>
<li>陈松溪，汤琤咏. <a href="/papers/HigDimen/3-1.pdf"><code>高维经验似然推断</code></a></li>
</ul>
<blockquote>
<p>研究两个问题，多元参数估计量的置信域和模型假设检验，并提出两个建议，新的估计方程和检验统计量。</p>
</blockquote>
<ul>
<li><a href="https://xs2.zidianzhan.net/citations?user=lZUH1lcAAAAJ&amp;hl=zh-CN&amp;oi=sra">汤琤咏</a>，冷琛雷. <a href="/papers/HigDimen/5.pdf"><code>高维惩罚经验似然</code></a></li>
</ul>
<blockquote>
<p>方江林提到，该类惩罚的思想是在进行参数估计的同时，利用惩罚函数将较小的系数估计值压缩为零，而将系数估计值较大的保留，在估计出系数的同时选择出重要变量。这可以同时实现变量选择和系数估计两个目标。惩罚变量选择普遍采用“损失函数+惩罚函数”的变量选择方法，类似地，惩罚经验似然通常也使用“经验似然比函数+惩罚函数”方式。该文首次将惩罚经验似然方法应用于高维，不过要求在 <code>$p &lt; n$</code> 情形下。</p>
</blockquote>
<blockquote>
<p>曾力立提到，该文将经验似然应用于高维变量选择。</p>
</blockquote>
<blockquote>
<p>何帮强提到，该文首次提出的惩罚经验似然（PEL）被用于分析多变量的均值向量和线性模型的发散数量回归系数。该文证实的PEL具有优点在来自非参数似然法的效率和适应性方面。另外，PEL方法具有使用数据来确定置信区域的形状和取向，与EL有相同优点并且不估计共协方差。</p>
</blockquote>
<ul>
<li><a href="https://xs2.zidianzhan.net/citations?user=rsT2stMAAAAJ&amp;hl=zh-CN&amp;oi=sra">冷琛雷</a>，汤琤咏. <a href="/papers/HigDimen/8.pdf"><code>惩罚经验似然与高维估计方程</code></a></li>
</ul>
<blockquote>
<p>方江林提到，该文将高维的惩罚经验似然方法推广到高维估计方程，仍要求<code>$p &lt; n$</code>。</p>
</blockquote>
<blockquote>
<p>何帮强提到，该文将PEL方法应用于一般估计方程的参数估计和变量选择，并显示PEL具有oracle特征。</p>
</blockquote>
<ul>
<li><a href="https://xs2.zidianzhan.net/citations?user=I5ZzKjAAAAAJ&amp;hl=zh-CN&amp;oi=sra">Lahiri</a>， <a href="https://xs2.zidianzhan.net/citations?user=Wf3jLKoAAAAJ&amp;hl=zh-CN&amp;oi=sra">Mukhopadhyay</a>. <a href="/papers/HigDimen/Lahiri2012.pdf"><code>高维中一种惩罚经验似然</code></a></li>
</ul>
<blockquote>
<p>方江林提到，当维数是超高维的，即 <code>$p &gt; n$</code> 时，该文研究了总体均值的惩罚经验似然推断，并给出了其统计量的渐近性质。</p>
</blockquote>
<h2 id="经验似然">经验似然</h2>
<ul>
<li>曾力立. <a href="/papers/HigDimen/%E6%9B%BE%E5%8A%9B%E7%AB%8B.caj"><code>高维线性回归模型下的经验似然</code></a></li>
</ul>
<blockquote>
<p>许多经典的低维数据处理方法，在处理髙维数据时面临着难以解决的困难。例如，传统的数据处理方法在处理高维数据时不能满足稳健性要求；高维导致空间的样本数变少，从而使得一些统计上的渐近性难以实现；维数的增加亦会导致数据的计算量迅速上升。</p>
</blockquote>
<blockquote>
<p>在这篇论文里，作者的主要目的是检验一个可能的高维线性回归模型的系数是否等于一个给定值。创新点：</p>
<ol>
<li>将传统经验似然方法里面的高维约束条件巧妙地变换成与维数无关的低维情形，以此构造出新的约束条件，再利用经验似然的方法解决相关问题。</li>
<li>在一般经验似然方法里加入了伪观测值，从而作出了一个新奇的调整。调整后的经验似然方法保留了之前方法的所有最优性准则．不仅如此，该方法下的区间覆盖率更接近于置信水平，而且还不需要Bartlett校正和Bootstrap方法里那么复杂的程序。</li>
<li>针对不同的维数，有区别地加入了约束条件的个数，一方面使得犯两类错误的概率令人满意，另一方面也大大地节省了计算成本。</li>
</ol>
</blockquote>
<blockquote>
<p>该文指出，线性模型的统计推断中 <code>$p$</code> 是 <code>$n$</code> 的指数阶的情况下的研究现状：</p>
<ol>
<li><code>$\beta$</code> 有很多分量为零，首先选出非零的分量（即变量选择，如Lasso），然后对被选出来的非零分量做统计推断。</li>
<li><code>$\beta$</code> 有很多分量不为零，简单地考虑变量选择是不够的，需要新的方法，借鉴<a href="https://xueshu.zidianzhan.net/citations?user=b3XlCawAAAAJ&amp;hl=zh-CN&amp;oi=sra">彭亮</a>在 <a href="/papers/HigDimen/7.pdf"><em>Empirical likelihood test for high dimensional linear models</em></a> 一文中的思想，通过一定手段——将样本数据分为两个部分，用每两个旧的观测值构造一个新的观测值——将约束条件与维数无关。</li>
</ol>
</blockquote>
<blockquote>
<p>该文思路：利用已有的观测值去构造 <code>$\omega_i(\beta)$</code>，构造出来的 <code>$\omega_i(\beta)$</code>需满足</p>
<ol>
<li><code>$E\omega_i(\beta_0)=0$</code>；</li>
<li><code>$E\omega_i(\beta_0)=0$</code> 非常接近于<code>$L_1$</code>范数。</li>
</ol>
</blockquote>
<blockquote>
<p>由此将经验似然的方法应用于估计式及 <code>$E\omega_i(\beta_0)=0$</code>，从而解决 <code>$\beta$</code> 有很多分量不为零的假设检验问题。曾力立将高维转换为一维进行考虑，并称其为简单经验似然。</p>
</blockquote>
<ul>
<li>方江林. <a href="/papers/HigDimen/11.caj"><code>维数发散的高维数据的经验似然</code></a></li>
</ul>
<blockquote>
<p>在样本维数 <code>$p$</code> 随容量 <code>$n$</code> 一起趋向无穷的情形下，本文研究了多个模型的经验似然推断，分别有半参数模型，可加危险率模型，异方差部分线性单指标模型，以及两样本问题（均值，线性模型系数之差）。</p>
</blockquote>
<blockquote>
<p>具体工作：</p>
<ol>
<li>利用经验似然方法构造了参数的估计量及其置信域。证明了在一定条件下，当样本维数和容量都趋向无穷情形时，经验似然比渐近分布为正态分布，并证明了通过经验似然方法得到的参数估计量具有一致性。</li>
<li>利用经验似然方法构造了参数分量的置信区间(置信域)。证明了在一定条件下，当样本维数发散时，通过经验似然方法得到的参数估计量具有一致性，并证明了关于参数分量的经验似然比渐近分布是 <code>$\chi^2_q$</code> 分布。</li>
<li>将惩罚经验似然方法推广到高维稀疏情形下模型的变量选择和参数估计问题。证明了在一定条件下，当样本维数发散时，惩罚经验似然比统计量具有渐近 <code>$\chi^2_q$</code> 分布，同时证明了惩罚经验似然方法具有Oracle性质。</li>
</ol>
</blockquote>
<blockquote>
<p>发表论文：</p>
<ol>
<li>方江林，<a href="https://mc.hunnu.edu.cn/info/1673/3366.htm">刘万荣</a>，<a href="https://xueshu.zidianzhan.net/citations?user=3yVTsEEAAAAJ&amp;hl=zh-CN&amp;oi=sra">Lu Xuewen</a>. <a href="/papers/HigDimen/11.pdf"><code>半参数模型的高维惩罚经验似然</code></a></li>
</ol>
</blockquote>
<ul>
<li>何帮强. <a href="/papers/HigDimen/%E4%BD%95%E5%B8%AE%E5%BC%BA.caj"><code>半参数带固定效应的面板数据模型的经验似然</code></a></li>
</ul>
<blockquote>
<p>见<a href="/cn/2022/10/20/panel">此</a>。</p>
</blockquote>
<ul>
<li><a href="https://xueshu.zidianzhan.net/citations?user=cakQLOsAAAAJ&amp;hl=zh-CN&amp;oi=sra">李高荣</a>. <a href="/papers/HigDimen/9.pdf"><code>高维变系数部分线性模型的经验似然</code></a></li>
</ul>
<blockquote>
<p>方江林提到，该文提出了改进的经验似然方法可以提高其统计推断的效率。</p>
</blockquote>
<ul>
<li>马昀蓓. <a href="/papers/HigDimen/%E9%A9%AC%E6%98%80%E8%93%93.caj"><code>相依误差下线性模型的经验似然</code></a></li>
</ul>
<blockquote>
</blockquote>
<ul>
<li>
<p><a href="https://xueshu.zidianzhan.net/citations?user=61q2xTYAAAAJ&amp;hl=zh-CN&amp;oi=sra">Heng Lian</a>. <a href="/papers/HigDimen/10.pdf"><code>高维删失情形下部分线性比率危险模型的经验似然</code></a></p>
</li>
<li>
<p>白璐. <a href="/papers/HigDimen/4.pdf"><code>固定和自适应设计下高维广义线性模型的经验似然检验</code></a></p>
</li>
</ul>
<blockquote>
</blockquote>
<ul>
<li>曾云辉. <a href="/papers/HigDimen/%E6%9B%BE%E4%BA%91%E8%BE%89.caj"><code>高维线性模型和部分线性模型的相合统计推断</code></a></li>
</ul>
<blockquote>
</blockquote>
<ul>
<li>马莹莹. <a href="/papers/HigDimen/%E9%A9%AC%E8%8E%B9%E8%8E%B9.caj"><code>高维数据均值和协差阵检验的经验似然方法</code></a></li>
</ul>
<blockquote>
</blockquote>
<h2 id="惩罚经验似然">惩罚经验似然</h2>
<ul>
<li>毛沥悦. <a href="/papers/HigDimen/%E6%AF%9B%E6%B2%A5%E6%82%A6.caj"><code>部分线性模型和广义线性模型的惩罚经验似然</code></a></li>
</ul>
<blockquote>
<p>第三章讨论高维情况下广义线性模型的参数估计与变量选择问题，通过通过适当的辅助随机变量研究了自适应Lasso下高维广义线性模型的惩罚经验似然。主要的结论有提出的方法具有Oracle性质以及在假设检验中构造的检验统计量的渐近分布为卡方分布。</p>
</blockquote>
<ul>
<li>文怡方. <a href="/papers/HigDimen/%E6%96%87%E6%80%A1%E6%96%B9.caj"><code>部分函数型线性模型的高维惩罚经验似然</code></a></li>
</ul>
<blockquote>
</blockquote>
<ul>
<li>吕升日. <a href="/papers/HigDimen/%E5%90%95%E5%8D%87%E6%97%A5.caj"><code>半参数回归模型的高维惩罚经验似然</code></a></li>
</ul>
<blockquote>
<p>在半参数回归模型中，当协变量的维度随着样本量的增大而增大，即当协变量维度较高时，将会遇到“维数祸根”等问题。将经验似然方法与惩罚函数相结合并应用于模型当中，可以有效的解决高维数据情况下的变量选择问题，从而降低模型的复杂度，解决模型在做预测时的不稳定性的问题。</p>
</blockquote>
<ul>
<li>李吉妮. <a href="/papers/HigDimen/%E6%9D%8E%E5%90%89%E5%A6%AE.caj"><code>单指标模型的高维惩罚经验似然</code></a></li>
</ul>
<blockquote>
<p>高维数据的变量选择问题。在处理高维数据时，单指标模型的降维特性有效地避免了“维数灾难问题，还抓住了高维数据的稀疏特性。在论文中考虑参数维数会随着样本容量的增大而同时增大的情形，对单指标模型提出了一种稳健的变量选择方法：基于SCAD惩罚函数及经验似然的惩罚经验似然。</p>
</blockquote>
<blockquote>
<p>论文发现，在一定正则条件下，参数维数随样本量同时增大的惩罚经验似然估计仍具有Oracle性质，即如果已知真实模型是稀疏的模型，则以概率趋向于1，惩罚经验似然确定模型的非零参数估计具有稀疏性（惩罚似然估计值应该有一个限制，这个限制自动将那些较小的估计系数设为，进而去掉，并删除对应的变量，从而降低模型的复杂度）。</p>
</blockquote>
<ul>
<li>刘琦. <a href="/papers/HigDimen/%E5%88%98%E7%90%A6.caj"><code>广义线性模型的高维惩罚经验似然</code></a></li>
</ul>
<blockquote>
</blockquote>
<h2 id="变量选择">变量选择</h2>
<ul>
<li><a href="https://xs2.zidianzhan.net/citations?user=sdw9roIAAAAJ&amp;hl=zh-CN&amp;oi=sra">Meinshausen N</a>. <a href="/papers/HigDimen/6.pdf"><code>高维回归p值</code></a></li>
</ul>
<blockquote>
<p>曾力立提到，该文研究了高维线性回归模型中的变量选择问题。</p>
</blockquote>
<ul>
<li>李玲玲. <a href="/papers/HigDimen/%E6%9D%8E%E7%8E%B2%E7%8E%B2.caj"><code>高维线性模型的变量选择</code></a></li>
</ul>
<blockquote>
</blockquote>
<ul>
<li>唐莹莹. <a href="/papers/HigDimen/%E5%94%90%E8%8E%B9%E8%8E%B9.caj"><code>两类空间面板数据模型的变量选择</code></a></li>
</ul>
<blockquote>
</blockquote>
<h2 id="em算法">EM算法</h2>
<ul>
<li>王富雅. <a href="/papers/HigDimen/%E7%8E%8B%E5%AF%8C%E9%9B%85.caj"><code>海量高维数据的分位数回归</code></a></li>
</ul>
<blockquote>
</blockquote>

        
        ]]>
      </description>
    </item>
    
    
    
    <item>
      <title>在读论文</title>
      <link>/cn/2022/09/23/paper/</link>
      <pubDate>Fri, 23 Sep 2022 00:00:00 +0000</pubDate>
      <author>Tan Jay</author>
      <guid>/cn/2022/09/23/paper/</guid>
      <description>
        <![CDATA[
        <!-- <font style="background-color: #FFFFCD;">[`PDF`](/papers/HigDimen/2.pdf)</font>
<font style="background-color: #F0FFFF;">[`NOTE`](/papers/HigDimen/2-note.pdf)</font>
<font style="background-color: #E6E6FA;">[](/papers/HigDimen/2-code.pdf)</font>
-->
<h2 id="高维数据-https-tang-jay-github-io-highdimen"><a href="https://tang-jay.github.io/HighDimen">高维数据</a></h2>
<ul>
<li>
<p>Nordmana, D.J. and Lahiri, S.N. (2014). A review of empirical likelihood methods for time series. <em>Journal of Statistical Planning and Inference, 155</em>, 1-18.
<a href="/papers/HigDimen/1.pdf"><code>PDF</code></a>
<a href="/papers/HigDimen/1-note.pdf"><code>NOTE</code></a></p>
</li>
<li>
<p>Shi, J. (2007). Empirical likelihood for higher dimensional linear models. <em>J. Sys. Sci. &amp; Math. Scis., 27</em>, 124-133.
<a href="/papers/HigDimen/2.pdf"><code>PDF</code></a>
<a href="/papers/HigDimen/2-note.pdf"><code>NOTE</code></a></p>
<ul>
<li><a href="/papers/HigDimen/2-1.pdf">1984 Ghosh M</a></li>
<li><a href="/papers/HigDimen/2-2.pdf">2000 Shi J</a></li>
<li><a href="/papers/HigDimen/2-3.pdf">1987 de Jong P</a></li>
</ul>
</li>
<li>
<p>Chen, S.X., Peng, L. and Qin, Y.L. (2009). Effects of data dimension on empirical likelihood. <em>Biometrika, 96</em>, 711-722.
<a href="/papers/HigDimen/3.pdf"><code>PDF</code></a>
<a href="/papers/HigDimen/3-note.pdf"><code>NOTE</code></a>
<a href="https://github.com/Tang-Jay/HigDimen/tree/main/2009ChenSongxi"><code>CODE</code></a></p>
</li>
<li>
<p>Chang, J.Y., Chen, S.X. and Tang, C.Y. (2020). High-dimensional empirical likelihood inference. <em>Biometrika, 00</em>, 1-21.
<a href="/papers/HigDimen/3-1.pdf"><code>PDF</code></a></p>
</li>
<li>
<p>Chang, J.Y., Chen, S.X. and Chen, X.H. (2015). High dimensional generalized empirical likelihood for moment restrictions with dependent data. <em>Journal of Econometrics,  185</em>, 283-304.
<a href="/papers/HigDimen/3-2.pdf"><code>PDF</code></a></p>
</li>
<li>
<p>N.L. Hjort, I.W. Mckeague, I.V. Keilegom, 2009. Extending the scop of empirical likelihood. <em>The Annals of Statistics. 37</em>, 1079-1111. <a href="/papers/HigDimen/1-1.pdf"><code>PDF</code></a></p>
</li>
</ul>

        
        ]]>
      </description>
    </item>
    
    
    
    <item>
      <title>对称矩阵</title>
      <link>/cn/2022/09/22/paper/</link>
      <pubDate>Thu, 22 Sep 2022 00:00:00 +0000</pubDate>
      <author>Tan Jay</author>
      <guid>/cn/2022/09/22/paper/</guid>
      <description>
        <![CDATA[
        <blockquote>
<p>Hessian矩阵、协方差矩阵、空间权重矩阵都是对称矩阵，相关的性质有必要了解一下。</p>
</blockquote>
<hr>
<h3 id="对称矩阵">对称矩阵</h3>
<ol>
<li><a href="https://mp.weixin.qq.com/s/mTiT8wNovGGAawlO-608_w">矩阵二次型及其性质</a></li>
<li><a href="/papers/SymMatrix/%E5%AF%B9%E7%A7%B0%E7%9F%A9%E9%98%B5%E7%9A%84%E4%B8%80%E4%BA%9B%E6%80%A7%E8%B4%A8%E5%92%8C%E5%AE%9A%E7%90%86_%E9%9F%A9%E6%8C%AF%E8%8A%B3.pdf">对称矩阵的一些性质和定理_韩振芳.pdf</a></li>
<li><a href="/papers/SymMatrix/%E5%AF%B9%E7%A7%B0%E7%9F%A9%E9%98%B5%E7%9A%84%E6%80%A7%E8%B4%A8%E5%8F%8A%E5%BA%94%E7%94%A8_%E5%8F%B8%E5%87%A4%E5%A8%9F.pdf">对称矩阵的性质及应用_司凤娟.pdf</a></li>
<li><a href="/papers/SymMatrix/%E5%AF%B9%E7%A7%B0%E7%9F%A9%E9%98%B5%E6%95%99%E4%B8%8E%E5%AD%A6_%E7%8E%8B%E5%AE%8F%E5%85%B4.pdf">对称矩阵教与学_王宏兴.pdf</a></li>
</ol>
<h3 id="反对称矩阵">反对称矩阵</h3>
<ol>
<li><a href="/papers/SymMatrix/%E5%AF%B9%E7%A7%B0%E7%9F%A9%E9%98%B5%E4%B8%8E%E5%8F%8D%E5%AF%B9%E7%A7%B0%E7%9F%A9%E9%98%B5%E7%9A%84%E8%8B%A5%E5%B9%B2%E6%80%A7%E8%B4%A8_%E6%AD%A6%E7%A7%80%E7%BE%8E.pdf">对称矩阵与反对称矩阵的若干性质_武秀美.pdf</a></li>
<li><a href="/papers/SymMatrix/%E5%AF%B9%E7%A7%B0%E7%9F%A9%E9%98%B5%E5%92%8C%E5%8F%8D%E5%AF%B9%E7%A7%B0%E7%9F%A9%E9%98%B5%E7%9A%84%E8%8B%A5%E5%B9%B2%E6%80%A7%E8%B4%A8_%E9%82%B9%E6%9C%AC%E5%BC%BA.pdf">对称矩阵和反对称矩阵的若干性质_邹本强.pdf</a></li>
<li><a href="/papers/SymMatrix/%E5%85%B3%E4%BA%8E%E5%AF%B9%E7%A7%B0%E7%9F%A9%E9%98%B5%E4%B8%8E%E5%8F%8D%E5%AF%B9%E7%A7%B0%E7%9F%A9%E9%98%B5%E7%9A%84%E8%8B%A5%E5%B9%B2%E6%80%A7%E8%B4%A8_%E6%9C%B1%E4%BA%9A%E8%8C%B9.pdf">关于对称矩阵与反对称矩阵的若干性质_朱亚茹.pdf</a></li>
</ol>
<h3 id="非对称矩阵">非对称矩阵</h3>
<ol>
<li><a href="/papers/SymMatrix/%E9%9D%9E%E5%AF%B9%E7%A7%B0%E6%AD%A3%E5%AE%9A%E7%9F%A9%E9%98%B5%E7%9A%84%E6%80%A7%E8%B4%A8_%E7%8E%8B%E4%B8%96%E6%81%92.pdf">非对称正定矩阵的性质_王世恒.pdf</a></li>
</ol>
<h3 id="对称矩阵应用">对称矩阵应用</h3>
<ol>
<li><a href="/papers/SymMatrix/%E5%AE%9E%E5%AF%B9%E7%A7%B0%E7%9F%A9%E9%98%B5%E7%9A%84%E6%80%A7%E8%B4%A8%E5%8F%8A%E5%85%B6%E5%BA%94%E7%94%A8_%E8%96%9B%E5%BB%BA%E6%98%8E.pdf">实对称矩阵的性质及其应用_薛建明.pdf</a></li>
<li><a href="/papers/SymMatrix/%E5%AE%9E%E5%AF%B9%E7%A7%B0%E7%9F%A9%E9%98%B5%E7%89%B9%E5%BE%81%E5%80%BC%E7%9A%84%E6%80%A7%E8%B4%A8%E5%8F%8A%E5%85%B6%E5%BA%94%E7%94%A8_%E6%9D%A8%E5%8F%AC.pdf">实对称矩阵特征值的性质及其应用_杨召.pdf</a></li>
</ol>
<h3 id="特征向量求法">特征向量求法</h3>
<ol>
<li><a href="/papers/SymMatrix/%E8%AE%A1%E7%AE%97%E5%AE%9E%E5%AF%B9%E7%A7%B0%E7%9F%A9%E9%98%B5%E7%89%B9%E5%BE%81%E5%80%BC%E7%89%B9%E5%BE%81%E5%90%91%E9%87%8F%E7%9A%84%E5%B9%82%E6%B3%95_%E6%9B%BE%E8%8E%89.pdf">计算实对称矩阵特征值特征向量的幂法_曾莉.pdf</a></li>
<li><a href="/papers/SymMatrix/%E5%88%A9%E7%94%A8%E7%89%B9%E5%BE%81%E7%9F%A9%E9%98%B5%E6%B1%82%E5%AE%9E%E5%AF%B9%E7%A7%B0%E7%9F%A9%E9%98%B5%E7%9A%84%E7%89%B9%E5%BE%81%E5%90%91%E9%87%8F_%E5%AD%9F%E5%AE%AA%E8%90%8C.pdf">利用特征矩阵求实对称矩阵的特征向量_孟宪萌.pdf</a></li>
</ol>
<h3 id="其他特殊矩阵">其他特殊矩阵</h3>
<ol>
<li><a href="https://mp.weixin.qq.com/s/Ci8iJ1YK3-AV8xWbGMJwrw">幂等矩阵、投影矩阵和Cochran定理</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzI3NzE3NDAxMg==&amp;mid=2247490095&amp;idx=1&amp;sn=16bc42b1823fc8067270b2a4428600f0&amp;chksm=eb6b19bcdc1c90aacb507441d5b4e4fb8a72ef1ffb4f2f161c44549aad063f11ccfaef076842&amp;scene=178&amp;cur_album_id=2185022661871960071#rd">Cochran定理</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzI3NzE3NDAxMg==&amp;mid=2247484817&amp;idx=1&amp;sn=74dc04683a2da5b0282be80f0e0505dc&amp;chksm=eb6b0602dc1c8f1447ec134259af88d42f2b67c10a3fde0026d4dbf594fb7955b4420bbbfd1a&amp;cur_album_id=2185022661871960071&amp;scene=190#rd">分块矩阵及其统计学应用</a></li>
</ol>

        
        ]]>
      </description>
    </item>
    
    
    
    <item>
      <title>秦导推荐</title>
      <link>/cn/2022/09/21/paper/</link>
      <pubDate>Wed, 21 Sep 2022 00:00:00 +0000</pubDate>
      <author>Tan Jay</author>
      <guid>/cn/2022/09/21/paper/</guid>
      <description>
        <![CDATA[
        <h2 id="摘要写作">摘要写作</h2>
<ul>
<li>
<p><a href="/papers/QinRecom/Abstra-1.pdf">范文 1</a></p>
</li>
<li>
<p><a href="/papers/QinRecom/Abstra-2.pdf">范文 2</a></p>
</li>
</ul>
<h2 id="空间数据">空间数据</h2>
<ul>
<li>
<p>秦永松 <a href="/papers/QinRecom/Qin-2.pdf"><code>空间计量经济模型的经验似然研究进展</code></a></p>
</li>
<li>
<p>Baltagi, B. H., Song, S. H., and Won K. (2003). Testing panel data regression models with spatial error correlation. <em>Journal of Econometrics, 117</em>, 123-150. <a href="/papers/QinRecom/Recom-1.pdf"><code>PDF</code></a></p>
</li>
<li>
<p>Baltagi, B. H. (2021). <em>Econometric Analysis of Panel Data</em>. Springer Cham. <a href="/papers/QinRecom/Recom-2.pdf"><code>PDF</code></a></p>
</li>
</ul>
<h2 id="经济类">经济类</h2>
<p>来自<a href="www.must.edu.mo/cn/msb/staff">澳门科技大学老师主页</a>。</p>
<ul>
<li><a href="/papers/QinRecom/Lin-1.pdf"><code>PDF1</code></a></li>
<li><a href="/papers/QinRecom/Lin-2.pdf"><code>PDF2</code></a></li>
<li><a href="/papers/QinRecom/Lin-3.pdf"><code>PDF3</code></a></li>
<li><a href="/papers/QinRecom/Lin-4.pdf"><code>PDF4</code></a></li>
<li><a href="/papers/QinRecom/Lin-5.pdf"><code>PDF5</code></a></li>
<li><a href="/papers/QinRecom/Lin-6.pdf"><code>PDF6</code></a></li>
</ul>
<!--
## 老师原稿
- [统计模拟和实证介绍](/papers/QinRecom/Qin-1.pdf) [`CODE`](/papers/QinRecom/Qin-1-code.R)
-->

        
        ]]>
      </description>
    </item>
    
    
  </channel>
</rss>
