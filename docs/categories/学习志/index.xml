<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>学习志 on Tan Jay | 唐 洁</title>
    <link>/categories/%E5%AD%A6%E4%B9%A0%E5%BF%97/</link>
    <description>Recent content in 学习志 on Tan Jay | 唐 洁</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 21 Oct 2022 00:00:00 +0000</lastBuildDate>
    <atom:link href="/categories/%E5%AD%A6%E4%B9%A0%E5%BF%97/" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>空间文献摘录</title>
      <link>/cn/2022/10/21/space/</link>
      <pubDate>Fri, 21 Oct 2022 00:00:00 +0000</pubDate>
      <author>Tan Jay</author>
      <guid>/cn/2022/10/21/space/</guid>
      <description>
        <![CDATA[
        <h2 id="空间模型">空间模型</h2>
<h3 id="秦永松-https-xueshu-zidianzhan-net-scholar-hl-zh-cn-as-sdt-0-2c5-q-ys-qin-empirical-likelihood-btng"><a href="https://xueshu.zidianzhan.net/scholar?hl=zh-CN&amp;as_sdt=0%2C5&amp;q=YS+Qin+empirical+likelihood&amp;btnG=">秦永松</a></h3>
<p><a href="/papers/QinRecom/Qin-2.pdf"><code>空间计量经济模型的经验似然研究进展</code></a></p>
<blockquote>
<p>这是一篇经验似然方法应用于空间模型的综述。</p>
</blockquote>
<p><a href="/papers/SpaModel/Qin-1.pdf"><code>含空间误差项的空间自回归模型的经验似然</code></a></p>

        
        ]]>
      </description>
    </item>
    
    
    
    <item>
      <title>面板文献摘录</title>
      <link>/cn/2022/10/20/panel/</link>
      <pubDate>Thu, 20 Oct 2022 00:00:00 +0000</pubDate>
      <author>Tan Jay</author>
      <guid>/cn/2022/10/20/panel/</guid>
      <description>
        <![CDATA[
        <h2 id="面板数据-https-xs2-zidianzhan-net-scholar-hl-zh-cn-as-sdt-0-2c5-q-panel-data-btng"><a href="https://xs2.zidianzhan.net/scholar?hl=zh-CN&amp;as_sdt=0%2C5&amp;q=panel+data&amp;btnG=">面板数据</a></h2>
<h3 id="何帮强-https-kns-cnki-net-kcms-detail-knetsearch-aspx-dbcode-cjfd-code-000021434404-sfield-au-skey-何帮强-uniplatform-nzkpt"><a href="https://kns.cnki.net/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;code=000021434404&amp;sfield=au&amp;skey=%E4%BD%95%E5%B8%AE%E5%BC%BA&amp;uniplatform=NZKPT">何帮强</a>.</h3>
<p><a href="/papers/HigDimen/%E4%BD%95%E5%B8%AE%E5%BC%BA.caj"><code>带固定效应 + 面板数据 + 半参数模型 + 经验似然</code></a></p>
<blockquote>
<p>此篇博士论文中研究了，带固定效应面板数据半参数模型的经验似然问题。</p>
</blockquote>
<p><a href="/papers/PanEmpir/HeBQ-2.pdf"><code>带固定效应 + 面板数据 + 部分线性模型 + 块经验似然</code></a></p>
<p><a href="/papers/PanEmpir/HeBQ-4.pdf"><code>带固定效应 + 面板数据 + 部分线性误差变量模型 + 统计推断</code></a></p>
<p><a href="/papers/PanEmpir/HeBQ-5.pdf"><code>带固定效应 + 面板数据 + 部分线性误差变量模型 + 惩罚经验似然</code></a></p>
<p><a href="/papers/PanEmpir/HeBQ-1.pdf"><code>带固定效应 + 面板数据 + 半变系数模型 + 经验似然</code></a></p>
<p><a href="/papers/PanEmpir/HeBQ-7.pdf"><code>鞅差序列 + 非线性半参数测量误差模型 + 经验似然</code></a></p>
<p><a href="/papers/PanEmpir/HeBQ-6.pdf"><code>删失数据 + 面板数据 + 半变系数变量误差模型 + 经验似然</code></a></p>
<h3 id="李高荣-https-xueshu-zidianzhan-net-citations-user-cakqlosaaaaj-hl-zh-cn-oi-sra"><a href="https://xueshu.zidianzhan.net/citations?user=cakQLOsAAAAJ&amp;hl=zh-CN&amp;oi=sra">李高荣</a></h3>
<p><a href="/papers/HigDimen/%E4%BD%95%E5%B8%AE%E5%BC%BA.caj"><code>带固定效应 + 面板数据 + 部分线性模型 + 经验似然</code></a></p>
<p><a href="/papers/HigDimen/9.pdf"><code>高维变系数 + 部分线性模型 + 经验似然</code></a></p>
<blockquote>
<p>方江林提到，该文提出了改进的经验似然方法可以提高其统计推断的效率。</p>
</blockquote>
<!--
[`Monotone empirical bayes test for the parameter of pareto distribution under random censorship
`](/papers/PanEmpir/HeBQ-3.pdf)

> 题外话，一不留神，开学两个月了，啥也没弄出来，顿挫感一下子就上来了。这学期还计划写一篇有意义的论文呢，现在看来，长路漫漫了。一方面呢，要保持顿挫感，它督促我珍惜时间继续努力，另一方面，不能让顿挫感泛滥，这会让我陷入无限的自责。
-->
        
        ]]>
      </description>
    </item>
    
    
    
    <item>
      <title>大脑突然就宕机了</title>
      <link>/cn/2022/10/17/note/</link>
      <pubDate>Mon, 17 Oct 2022 00:00:00 +0000</pubDate>
      <author>Tan Jay</author>
      <guid>/cn/2022/10/17/note/</guid>
      <description>
        <![CDATA[
        <p>看论文看着看着，看见“半参数模型”几个字，愣了一下，我竟然对这个朝夕相伴这么久的名词，还不知道究竟是个啥，自己研究的模型到底算不算半参数模型？头晕😵‍💫～</p>
<p>上网搜一搜，大家给的答案：</p>
<ul>
<li><a href="https://www.jianshu.com/p/a97c5a0718f8">半参数模型</a></li>
<li><a href="https://blog.sciencenet.cn/blog-941132-1080151.html">杨立坚写的统计学科普</a></li>
<li><a href="https://www.zhihu.com/question/24373415">如何理解统计学半参数的概念？</a></li>
</ul>
<p>选择一个答案记录一下，</p>
<p>参数回归是事先假定模型的形式，然后用数据去估计这个模型的系数。而非参数回归则是不假定模型形式，直接从数据来拟合模型。参数回归最基本的是线性模型，非参数回归最简单的最近邻方法。而半参数回归则是，模型中有一部分的结构是已知的，需要估计参数，而另外一部分结构未知。</p>
<p>比如有<code>$X_1$</code>与<code>$X_2$</code>两个自变量，<code>$Y$</code>为因变量，我们可以对回归函数建模为：</p>
<p>$$E[Y|X_1, X_2]= \alpha + \beta X_1 + h(X_2)$$</p>
<p>那么，对<code>$h(X_2)$</code>的分析就是非参的，而对<code>$X_1$</code>的分析为参数的。但如果将其视作整体，其实整个模型严格意义上还是非参的。</p>

        
        ]]>
      </description>
    </item>
    
    
    
    <item>
      <title>高维可尝试方向</title>
      <link>/cn/2022/10/17/higdim/</link>
      <pubDate>Mon, 17 Oct 2022 00:00:00 +0000</pubDate>
      <author>Tan Jay</author>
      <guid>/cn/2022/10/17/higdim/</guid>
      <description>
        <![CDATA[
        <h2 id="高维问题">高维问题</h2>
<p>曾力立说，</p>
<ol>
<li>传统的数据处理方法在处理高维数据时不能满足稳健性要求；</li>
<li>高维导致空间的样本数变少，从而使得一些统计上的渐近性难以实现；</li>
<li>维数的增加亦会导致数据的计算量迅速上升。</li>
</ol>
<p>方江林说，</p>
<ol>
<li>维数的增大会导致“维数灾难”问题；</li>
<li>经典大样本统计推断理论一般都是建立在维数固定且相对较小，而样本量趋于无穷的假设下，在数据维数p随着样本容量n一起趋向无穷时，特别是在“超高维”(p &gt; n)数据情形下，经典统计理论的结论可能不再有效。</li>
</ol>
<h2 id="方向">方向</h2>
<h3 id="方向一">方向一</h3>
<p>根据 <strong>石坚</strong><a href="/papers/HigDimen/2.pdf">《高维线性模型中的经验似然》</a>思想，说明高维空间模型中，在适当的正则条件下，可对经验似然比统计量进行修正，并且修正后的经验似然比统计量服从标准正态分布。</p>
<p>实际进展<a href="https://tang-jay.github.io/HighDimen">见此</a>。</p>
<h3 id="方向二">方向二</h3>
<p>当 <code>$\beta$</code> 有很多分量为零，可以做变量选择，比如Lasso、惩罚经验似然，先选出非零的分量，然后对被选出来的非零分量做统计推断。</p>
<h3 id="方向三">方向三</h3>
<p>当 <code>$\beta$</code> 有很多分量不为零，简单地考虑变量选择是不够的，根据 <strong>曾力立</strong><a href="/papers/HigDimen/4.caj">《高维线性回归模型下的经验似然》</a>思想，说明高维空间模型中可以建立简单经验似然统计量，并且证明该统计量服从 <code>$\chi^2_1$</code>，从模拟的角度说明，犯两类错误的概率令人满意，且大大节省了计算成本。</p>

        
        ]]>
      </description>
    </item>
    
    
    
    <item>
      <title>高维文献摘录</title>
      <link>/cn/2022/10/16/higdim/</link>
      <pubDate>Sun, 16 Oct 2022 00:00:00 +0000</pubDate>
      <author>Tan Jay</author>
      <guid>/cn/2022/10/16/higdim/</guid>
      <description>
        <![CDATA[
        <!-- 
- [``](/papers/HigDimen/曾力立.caj)
> 
-->
<h2 id="奠基">奠基</h2>
<ul>
<li>石坚. <a href="/papers/HigDimen/2.pdf"><code>高维线性模型中的经验似然</code></a></li>
</ul>
<blockquote>
<p>当协变量的维数随样本量增加时，常规的经验似然推断失效，在适当的正则条件下，对修正的经验似然比统计量给出了渐近分布理论。</p>
</blockquote>
<blockquote>
<p>曾力立提到，该论文表明，当协变量维数以某种合理的速度趋于无穷大时，我们仍可以利用经验似然方法构造 <code>$\beta$</code> 的置信域，不过此时有关临界值的确定依赖于正态分布而非卡方分布。</p>
</blockquote>
<ul>
<li><a href="https://xueshu.zidianzhan.net/citations?user=pGvWCH4AAAAJ&amp;hl=zh-CN&amp;oi=sra">Hjort et al.</a> <a href="/papers/HigDimen/1-1.pdf"><code>拓展经验似然应用范围</code></a></li>
</ul>
<blockquote>
<p>方江林提到，当 <code>$p=o_p(n^{1/3}) \to \infty$</code> 时，在一定条件下，该文得出了经验似然比统计量渐近分布为正态分布的结论。</p>
</blockquote>
<blockquote>
<p>曾力立提到，该文在基于plug-in估计对经验似然方法做了一个推广研究。</p>
</blockquote>
<ul>
<li>陈松溪，<a href="https://xueshu.zidianzhan.net/citations?user=b3XlCawAAAAJ&amp;hl=zh-CN&amp;oi=sra">彭亮</a>. <a href="/papers/HigDimen/3.pdf"><code>数据维数对经验似然的影响</code></a></li>
</ul>
<blockquote>
<p>在一般的多元模型下，该文评估了数据维数对高维数据经验似然比的渐近正态性的影响，指出多元随机向量各分量之间的数据维数和相关性直接通过协方差矩阵的迹和特征值来影响经验似然。</p>
</blockquote>
<blockquote>
<p>方江林提到，该文是在Hjort基础上，进一步研究了样本维数对经验似然方法的影响，证明了当 <code>$p=o_p(n^{1/2}) \to \infty$</code> 时，经验似然方法仍然适用，改进了Hjort的结果。</p>
</blockquote>
<blockquote>
<p>曾力立提到，该文在多元模型下研究了均值的渐近性质。</p>
</blockquote>
<blockquote>
<p>毛沥悦提到，该文证明了当参数的维数变化时，经验似然方法仍然有效。</p>
</blockquote>
<ul>
<li>陈松溪，汤琤咏. <a href="/papers/HigDimen/3-1.pdf"><code>高维经验似然推断</code></a></li>
</ul>
<blockquote>
<p>研究两个问题，多元参数估计量的置信域和模型假设检验，并提出两个建议，新的估计方程和检验统计量。</p>
</blockquote>
<ul>
<li><a href="https://xs2.zidianzhan.net/citations?user=lZUH1lcAAAAJ&amp;hl=zh-CN&amp;oi=sra">汤琤咏</a>，冷琛雷. <a href="/papers/HigDimen/5.pdf"><code>高维惩罚经验似然</code></a></li>
</ul>
<blockquote>
<p>方江林提到，该类惩罚的思想是在进行参数估计的同时，利用惩罚函数将较小的系数估计值压缩为零，而将系数估计值较大的保留，在估计出系数的同时选择出重要变量。这可以同时实现变量选择和系数估计两个目标。惩罚变量选择普遍采用“损失函数+惩罚函数”的变量选择方法，类似地，惩罚经验似然通常也使用“经验似然比函数+惩罚函数”方式。该文首次将惩罚经验似然方法应用于高维，不过要求在 <code>$p &lt; n$</code> 情形下。</p>
</blockquote>
<blockquote>
<p>曾力立提到，该文将经验似然应用于高维变量选择。</p>
</blockquote>
<blockquote>
<p>何帮强提到，该文首次提出的惩罚经验似然（PEL）被用于分析多变量的均值向量和线性模型的发散数量回归系数。该文证实的PEL具有优点在来自非参数似然法的效率和适应性方面。另外，PEL方法具有使用数据来确定置信区域的形状和取向，与EL有相同优点并且不估计共协方差。</p>
</blockquote>
<ul>
<li><a href="https://xs2.zidianzhan.net/citations?user=rsT2stMAAAAJ&amp;hl=zh-CN&amp;oi=sra">冷琛雷</a>，汤琤咏. <a href="/papers/HigDimen/8.pdf"><code>惩罚经验似然与高维估计方程</code></a></li>
</ul>
<blockquote>
<p>方江林提到，该文将高维的惩罚经验似然方法推广到高维估计方程，仍要求<code>$p &lt; n$</code>。</p>
</blockquote>
<blockquote>
<p>何帮强提到，该文将PEL方法应用于一般估计方程的参数估计和变量选择，并显示PEL具有oracle特征。</p>
</blockquote>
<ul>
<li><a href="https://xs2.zidianzhan.net/citations?user=I5ZzKjAAAAAJ&amp;hl=zh-CN&amp;oi=sra">Lahiri</a>， <a href="https://xs2.zidianzhan.net/citations?user=Wf3jLKoAAAAJ&amp;hl=zh-CN&amp;oi=sra">Mukhopadhyay</a>. <a href="/papers/HigDimen/Lahiri2012.pdf"><code>高维中一种惩罚经验似然</code></a></li>
</ul>
<blockquote>
<p>方江林提到，当维数是超高维的，即 <code>$p &gt; n$</code> 时，该文研究了总体均值的惩罚经验似然推断，并给出了其统计量的渐近性质。</p>
</blockquote>
<h2 id="经验似然">经验似然</h2>
<ul>
<li>曾力立. <a href="/papers/HigDimen/%E6%9B%BE%E5%8A%9B%E7%AB%8B.caj"><code>高维线性回归模型下的经验似然</code></a></li>
</ul>
<blockquote>
<p>许多经典的低维数据处理方法，在处理髙维数据时面临着难以解决的困难。例如，传统的数据处理方法在处理高维数据时不能满足稳健性要求；高维导致空间的样本数变少，从而使得一些统计上的渐近性难以实现；维数的增加亦会导致数据的计算量迅速上升。</p>
</blockquote>
<blockquote>
<p>在这篇论文里，作者的主要目的是检验一个可能的高维线性回归模型的系数是否等于一个给定值。创新点：</p>
<ol>
<li>将传统经验似然方法里面的高维约束条件巧妙地变换成与维数无关的低维情形，以此构造出新的约束条件，再利用经验似然的方法解决相关问题。</li>
<li>在一般经验似然方法里加入了伪观测值，从而作出了一个新奇的调整。调整后的经验似然方法保留了之前方法的所有最优性准则．不仅如此，该方法下的区间覆盖率更接近于置信水平，而且还不需要Bartlett校正和Bootstrap方法里那么复杂的程序。</li>
<li>针对不同的维数，有区别地加入了约束条件的个数，一方面使得犯两类错误的概率令人满意，另一方面也大大地节省了计算成本。</li>
</ol>
</blockquote>
<blockquote>
<p>该文指出，线性模型的统计推断中 <code>$p$</code> 是 <code>$n$</code> 的指数阶的情况下的研究现状：</p>
<ol>
<li><code>$\beta$</code> 有很多分量为零，首先选出非零的分量（即变量选择，如Lasso），然后对被选出来的非零分量做统计推断。</li>
<li><code>$\beta$</code> 有很多分量不为零，简单地考虑变量选择是不够的，需要新的方法，借鉴<a href="https://xueshu.zidianzhan.net/citations?user=b3XlCawAAAAJ&amp;hl=zh-CN&amp;oi=sra">彭亮</a>在 <a href="/papers/HigDimen/7.pdf"><em>Empirical likelihood test for high dimensional linear models</em></a> 一文中的思想，通过一定手段——将样本数据分为两个部分，用每两个旧的观测值构造一个新的观测值——将约束条件与维数无关。</li>
</ol>
</blockquote>
<blockquote>
<p>该文思路：利用已有的观测值去构造 <code>$\omega_i(\beta)$</code>，构造出来的 <code>$\omega_i(\beta)$</code>需满足</p>
<ol>
<li><code>$E\omega_i(\beta_0)=0$</code>；</li>
<li><code>$E\omega_i(\beta_0)=0$</code> 非常接近于<code>$L_1$</code>范数。</li>
</ol>
</blockquote>
<blockquote>
<p>由此将经验似然的方法应用于估计式及 <code>$E\omega_i(\beta_0)=0$</code>，从而解决 <code>$\beta$</code> 有很多分量不为零的假设检验问题。曾力立将高维转换为一维进行考虑，并称其为简单经验似然。</p>
</blockquote>
<ul>
<li>方江林. <a href="/papers/HigDimen/11.caj"><code>维数发散的高维数据的经验似然</code></a></li>
</ul>
<blockquote>
<p>在样本维数 <code>$p$</code> 随容量 <code>$n$</code> 一起趋向无穷的情形下，本文研究了多个模型的经验似然推断，分别有半参数模型，可加危险率模型，异方差部分线性单指标模型，以及两样本问题（均值，线性模型系数之差）。</p>
</blockquote>
<blockquote>
<p>具体工作：</p>
<ol>
<li>利用经验似然方法构造了参数的估计量及其置信域。证明了在一定条件下，当样本维数和容量都趋向无穷情形时，经验似然比渐近分布为正态分布，并证明了通过经验似然方法得到的参数估计量具有一致性。</li>
<li>利用经验似然方法构造了参数分量的置信区间(置信域)。证明了在一定条件下，当样本维数发散时，通过经验似然方法得到的参数估计量具有一致性，并证明了关于参数分量的经验似然比渐近分布是 <code>$\chi^2_q$</code> 分布。</li>
<li>将惩罚经验似然方法推广到高维稀疏情形下模型的变量选择和参数估计问题。证明了在一定条件下，当样本维数发散时，惩罚经验似然比统计量具有渐近 <code>$\chi^2_q$</code> 分布，同时证明了惩罚经验似然方法具有Oracle性质。</li>
</ol>
</blockquote>
<blockquote>
<p>发表论文：</p>
<ol>
<li>方江林，<a href="https://mc.hunnu.edu.cn/info/1673/3366.htm">刘万荣</a>，<a href="https://xueshu.zidianzhan.net/citations?user=3yVTsEEAAAAJ&amp;hl=zh-CN&amp;oi=sra">Lu Xuewen</a>. <a href="/papers/HigDimen/11.pdf"><code>半参数模型的高维惩罚经验似然</code></a></li>
</ol>
</blockquote>
<ul>
<li>何帮强. <a href="/papers/HigDimen/%E4%BD%95%E5%B8%AE%E5%BC%BA.caj"><code>半参数带固定效应的面板数据模型的经验似然</code></a></li>
</ul>
<blockquote>
<p>见<a href="/cn/2022/10/20/panel">此</a>。</p>
</blockquote>
<ul>
<li><a href="https://xueshu.zidianzhan.net/citations?user=cakQLOsAAAAJ&amp;hl=zh-CN&amp;oi=sra">李高荣</a>. <a href="/papers/HigDimen/9.pdf"><code>高维变系数部分线性模型的经验似然</code></a></li>
</ul>
<blockquote>
<p>方江林提到，该文提出了改进的经验似然方法可以提高其统计推断的效率。</p>
</blockquote>
<ul>
<li>马昀蓓. <a href="/papers/HigDimen/%E9%A9%AC%E6%98%80%E8%93%93.caj"><code>相依误差下线性模型的经验似然</code></a></li>
</ul>
<blockquote>
</blockquote>
<ul>
<li>
<p><a href="https://xueshu.zidianzhan.net/citations?user=61q2xTYAAAAJ&amp;hl=zh-CN&amp;oi=sra">Heng Lian</a>. <a href="/papers/HigDimen/10.pdf"><code>高维删失情形下部分线性比率危险模型的经验似然</code></a></p>
</li>
<li>
<p>白璐. <a href="/papers/HigDimen/4.pdf"><code>固定和自适应设计下高维广义线性模型的经验似然检验</code></a></p>
</li>
</ul>
<blockquote>
</blockquote>
<ul>
<li>曾云辉. <a href="/papers/HigDimen/%E6%9B%BE%E4%BA%91%E8%BE%89.caj"><code>高维线性模型和部分线性模型的相合统计推断</code></a></li>
</ul>
<blockquote>
</blockquote>
<ul>
<li>马莹莹. <a href="/papers/HigDimen/%E9%A9%AC%E8%8E%B9%E8%8E%B9.caj"><code>高维数据均值和协差阵检验的经验似然方法</code></a></li>
</ul>
<blockquote>
</blockquote>
<h2 id="惩罚经验似然">惩罚经验似然</h2>
<ul>
<li>毛沥悦. <a href="/papers/HigDimen/%E6%AF%9B%E6%B2%A5%E6%82%A6.caj"><code>部分线性模型和广义线性模型的惩罚经验似然</code></a></li>
</ul>
<blockquote>
<p>第三章讨论高维情况下广义线性模型的参数估计与变量选择问题，通过通过适当的辅助随机变量研究了自适应Lasso下高维广义线性模型的惩罚经验似然。主要的结论有提出的方法具有Oracle性质以及在假设检验中构造的检验统计量的渐近分布为卡方分布。</p>
</blockquote>
<ul>
<li>文怡方. <a href="/papers/HigDimen/%E6%96%87%E6%80%A1%E6%96%B9.caj"><code>部分函数型线性模型的高维惩罚经验似然</code></a></li>
</ul>
<blockquote>
</blockquote>
<ul>
<li>吕升日. <a href="/papers/HigDimen/%E5%90%95%E5%8D%87%E6%97%A5.caj"><code>半参数回归模型的高维惩罚经验似然</code></a></li>
</ul>
<blockquote>
<p>在半参数回归模型中，当协变量的维度随着样本量的增大而增大，即当协变量维度较高时，将会遇到“维数祸根”等问题。将经验似然方法与惩罚函数相结合并应用于模型当中，可以有效的解决高维数据情况下的变量选择问题，从而降低模型的复杂度，解决模型在做预测时的不稳定性的问题。</p>
</blockquote>
<ul>
<li>李吉妮. <a href="/papers/HigDimen/%E6%9D%8E%E5%90%89%E5%A6%AE.caj"><code>单指标模型的高维惩罚经验似然</code></a></li>
</ul>
<blockquote>
<p>高维数据的变量选择问题。在处理高维数据时，单指标模型的降维特性有效地避免了“维数灾难问题，还抓住了高维数据的稀疏特性。在论文中考虑参数维数会随着样本容量的增大而同时增大的情形，对单指标模型提出了一种稳健的变量选择方法：基于SCAD惩罚函数及经验似然的惩罚经验似然。</p>
</blockquote>
<blockquote>
<p>论文发现，在一定正则条件下，参数维数随样本量同时增大的惩罚经验似然估计仍具有Oracle性质，即如果已知真实模型是稀疏的模型，则以概率趋向于1，惩罚经验似然确定模型的非零参数估计具有稀疏性（惩罚似然估计值应该有一个限制，这个限制自动将那些较小的估计系数设为，进而去掉，并删除对应的变量，从而降低模型的复杂度）。</p>
</blockquote>
<ul>
<li>刘琦. <a href="/papers/HigDimen/%E5%88%98%E7%90%A6.caj"><code>广义线性模型的高维惩罚经验似然</code></a></li>
</ul>
<blockquote>
</blockquote>
<h2 id="变量选择">变量选择</h2>
<ul>
<li><a href="https://xs2.zidianzhan.net/citations?user=sdw9roIAAAAJ&amp;hl=zh-CN&amp;oi=sra">Meinshausen N</a>. <a href="/papers/HigDimen/6.pdf"><code>高维回归p值</code></a></li>
</ul>
<blockquote>
<p>曾力立提到，该文研究了高维线性回归模型中的变量选择问题。</p>
</blockquote>
<ul>
<li>李玲玲. <a href="/papers/HigDimen/%E6%9D%8E%E7%8E%B2%E7%8E%B2.caj"><code>高维线性模型的变量选择</code></a></li>
</ul>
<blockquote>
</blockquote>
<ul>
<li>唐莹莹. <a href="/papers/HigDimen/%E5%94%90%E8%8E%B9%E8%8E%B9.caj"><code>两类空间面板数据模型的变量选择</code></a></li>
</ul>
<blockquote>
</blockquote>
<h2 id="em算法">EM算法</h2>
<ul>
<li>王富雅. <a href="/papers/HigDimen/%E7%8E%8B%E5%AF%8C%E9%9B%85.caj"><code>海量高维数据的分位数回归</code></a></li>
</ul>
<blockquote>
</blockquote>

        
        ]]>
      </description>
    </item>
    
    
    
    <item>
      <title>深度思考</title>
      <link>/cn/2022/10/11/note/</link>
      <pubDate>Tue, 11 Oct 2022 00:00:00 +0000</pubDate>
      <author>Tan Jay</author>
      <guid>/cn/2022/10/11/note/</guid>
      <description>
        <![CDATA[
        <blockquote>
<p>深入思考让勤奋更有意义。</p>
</blockquote>
<hr>
<p>这是一篇摘记<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>。</p>
<h2 id="必要性">必要性</h2>
<p>斯坦福大学教授卡罗尔·德伟克，曾将思维模式分为三种：感性思维、逻辑思维和结构思维。</p>
<p>感性思维属于点状思维，对事件没有延伸思考，只是基于某个情绪点进行主观判断。</p>
<p>逻辑思维是线性思维，由一个原因，推出一个结果。相较点状思维，线性思维有很大提升，但思考维度过于单一。但当人们陷入线性思维，不再挖掘其他其可能性，同样难有作为。</p>
<p>结构思维，则是一种面状思维。拥有面状思维的人，主动挖掘更多可能性，最终给出兼顾各方的最优判断。而这，就是深度思考的能力。</p>
<p>没有深入触及问题的根源，所有行动都是徒劳。</p>
<blockquote>
<p>如果给我1个小时去解一道题目，我会用55分钟去思考，只要思考正确，那么5分钟足够给出答案。</p>
</blockquote>
<blockquote>
<p>——爱因斯坦</p>
</blockquote>
<blockquote>
<p>人之所以脱颖而出，首先必然是思考力的出类拔萃。</p>
</blockquote>
<blockquote>
<p>——香奈儿前CEO莫琳·希凯</p>
</blockquote>
<blockquote>
<p><img src="/images/1011.png" alt=""></p>
</blockquote>
<blockquote>
<p>——《认知突围》</p>
</blockquote>
<h2 id="实现途径">实现途径</h2>
<p>深度思考几乎是唯一一个，对每个人而言，没有门槛的逆袭机会。而想要培养深度思考的能力，一个很好的方法就是“维度进阶”。(作家刘润)</p>
<ol>
<li>时间维度。</li>
</ol>
<blockquote>
<p>如果把你做每件事的眼光放到三年以内，和你同台竞技的人会很多；但如果你把眼光放到未来七年，那么能和你竞争的就会很少，因为很少有人愿意做如此长远的打算。</p>
</blockquote>
<blockquote>
<p>——亚马逊CEO贝索斯</p>
</blockquote>
<ol start="2">
<li>空间维度。</li>
</ol>
<blockquote>
<p>生活中我们大多数人，最初的思考空间都局限于狭窄的一点。可当你拓宽思维空间，将其他因素，比如保险丝（熔断）有关的设备，纳入考虑范围，我们的思维便有了维度。随着考虑因素不断增加，我们的思考在同一维度上，便实现了由点到线再到面的蜕变。当我们的思考到达一定深度，在某个瞬间就会有一个小点突破平面。而正是通过这一点的发散，我们最终拥有更为立体的思维模型。</p>
</blockquote>
<blockquote>
<p>——公众号《洞见》</p>
</blockquote>
<h2 id="总结">总结</h2>
<p>每一次深度思考，其实都是在打破自己，打破单一浅显的思维框架，打破陈腐的认知和经验。</p>
<blockquote>
<p>重复且长时间的无尽忙碌，只要条件具备，大部分人都可以做到。难的是思考。没有深入的思考，勤奋就没有意义。</p>
</blockquote>
<blockquote>
<p>——《思考，快与慢》作者卡尼曼</p>
</blockquote>
<p>(个人补充，文章强调了深度思考的重要性以及怎么达到，我很感谢这样的良心作者，将自己所思所悟分享给大家，我很受益。就“没有深入的思考，勤奋就没有意义”这句话而言，他是强调了我们应该进行深度思考，只是反过来看，思考是阅历之后思想的沉淀，当我们没有阅历没有想法的时候，也不要否定勤奋，勤奋是获得思想这种物料的渠道，换而言之，我觉得这样说更好，“深入思考让勤奋更有意义，深度思考让勤奋有了好的方向”。)</p>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>公众号：<em>洞见</em>。<a href="https://mp.weixin.qq.com/s/gWGSpEEdPvs8djKcjMzsfQ">一个人成长最快的方式：深度思考</a>。&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>

        
        ]]>
      </description>
    </item>
    
    
    
    <item>
      <title>学习风格测试</title>
      <link>/cn/2022/09/27/vark/</link>
      <pubDate>Tue, 27 Sep 2022 00:00:00 +0000</pubDate>
      <author>Tan Jay</author>
      <guid>/cn/2022/09/27/vark/</guid>
      <description>
        <![CDATA[
        <p>专属学习风格测试<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>通过视觉（Visual）、听觉（Auditory）、阅读（Reading）和动感（Kinesthetic）四个角度评估人类的学习模式。</p>
<h1 id="测试结果">测试结果</h1>
<p>视觉38%、听觉13%、阅读6%和动感44%。(🤔检测结果感觉有那么点点像，能动手绝不瞎逼逼；能自己解决，绝不哭唧唧。)</p>
<p style="text-align: center;">
	<img src="/images/vark.png" alt="WechatIMG435" style="zoom:80%;" />
</p>
<h2 id="主导学习风格">主导学习风格</h2>
<h3 id="运动型-44">运动型 44%</h3>
<ul>
<li>
<p>关键词：动手及实践能力 喜欢尝试 在实验和实习中成长</p>
</li>
<li>
<p>报告：你有极强的动手能力和实践能力；对于亲身经历过的事物记忆力出众。比起抽象的理论，你更偏好看的见、摸得着的事物和亲身经历的体验。你喜欢尝试，善于从失败的案例中吸取经验。比起单纯的讲解，你更喜欢通过观察示例、做应用题、亲自尝试等办法学习。在实验和实习中，你更容易学习和成长。</p>
</li>
<li>
<p>建议：</p>
<ul>
<li>在学习时如果有可能的话，应该多去实地参观考察；</li>
<li>把握一切实际运用理论知识的机会。</li>
<li>多参考老师给出的真实例子，尽量用实际行动践行理论知识。</li>
<li>多尝试使用视觉、触觉、味觉等感官。</li>
<li>亲自参与与及时反馈对于你十分重要；多说多做非常有利于你的提高。</li>
</ul>
</li>
</ul>
<h2 id="其他学习风格">其他学习风格</h2>
<h3 id="视觉型-38">视觉型 38%</h3>
<ul>
<li>
<p>关键词：观察能力 图像信息 对流程图，涂画图标的记忆力较强</p>
</li>
<li>
<p>报告：你有很好观察能力；善于记忆图像信息，对可视化信息的理解能力更强。相比简单的文字表述，你更喜欢有丰富图形变化和空间安排的页面，例如带有示例图的教科书和颜色变化丰富的讲义。在听课时你更偏好善用肢体语言、图形语言和幻灯片展示的老师。你对于逻辑清楚的流程图、形象生动的图画图表的记忆能力较强。</p>
</li>
<li>
<p>建议：</p>
<ul>
<li>在记笔记时多尝试用不同颜色的笔；制作不同的图形分区；变换笔记的排列格式，这样更利于你的理解记忆。</li>
<li>处理信息时多使用思维导图和直观可视的图表，这样有助于你快速get到逻辑关系和重点信息。</li>
<li>将重点内容用斜体、加粗、下划线、高亮的显著的视觉符号区分。</li>
<li>有丰富图像信息的电影、电视剧于你而言是很好的学习材料。</li>
<li>详细的指示图、说明图在你的学习过程中至关重要。</li>
</ul>
</li>
</ul>
<h3 id="听觉型-13">听觉型 13%</h3>
<ul>
<li>
<p>关键词：听觉敏锐 喜欢聆听交流 对理论，示例等有很强的记忆力</p>
</li>
<li>
<p>建议：</p>
<ul>
<li>在挑选学习材料时尽量选择有音频的图书。</li>
<li>多参与讨论和回答问题，沟通和聆听会增强你的记忆效率。</li>
<li>比起自己读书你更适合听讲。</li>
<li>找机会向他人讲述你的学习内容也是不错的选择。</li>
<li>你可以尝试复述、朗读笔记、口头摘要等形式的学习方法。</li>
<li>音频类的学习材料都十分适合你，如广播剧、电影、新闻。</li>
<li>场景化的沟通交流非常适合提高你的听力与口语；在学习中应该大声的朗读和沟通。</li>
</ul>
</li>
</ul>
<h3 id="读写型-6">读写型 6%</h3>
<ul>
<li>
<p>关键词：阅读理解能力 倾向于文字，适合简明的摘要和报告</p>
</li>
<li>
<p>建议：</p>
<ul>
<li>在学习时应该留出足够的时间做笔记。</li>
<li>定期进行书面总结或写日记对你而言都是很好的学习策略。</li>
<li>反复的书写和默读有助于你更快记忆。</li>
<li>尝试将各种图表转化成文字。</li>
<li>书籍和杂志文章都是十分适合你的学习材料，最好选择带有文字讲解的版本。</li>
</ul>
</li>
</ul>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>公众号：丹尼听力。<a href="https://mp.weixin.qq.com/s/qmQSzW4H14rAP-bw9baGeA"><em>国外超火的「学习风格测试」来啦，测出你的学习天赋！</em></a>&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>

        
        ]]>
      </description>
    </item>
    
    
    
    <item>
      <title>R画图笔记</title>
      <link>/cn/2022/09/26/codes/</link>
      <pubDate>Mon, 26 Sep 2022 00:00:00 +0000</pubDate>
      <author>Tan Jay</author>
      <guid>/cn/2022/09/26/codes/</guid>
      <description>
        <![CDATA[
        <p>最近努力在复现论文上的QQ图<br>
顺便将知道的R画图的代码一并整理出来   <br>
用Bookdown很好地展示<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>出来～<br>
继续加油！</p>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>唐洁,<a href="https://tang-jay.github.io/RBook">《R语言画图》</a>&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>

        
        ]]>
      </description>
    </item>
    
    
    
    <item>
      <title>在读论文</title>
      <link>/cn/2022/09/23/paper/</link>
      <pubDate>Fri, 23 Sep 2022 00:00:00 +0000</pubDate>
      <author>Tan Jay</author>
      <guid>/cn/2022/09/23/paper/</guid>
      <description>
        <![CDATA[
        <!-- <font style="background-color: #FFFFCD;">[`PDF`](/papers/HigDimen/2.pdf)</font>
<font style="background-color: #F0FFFF;">[`NOTE`](/papers/HigDimen/2-note.pdf)</font>
<font style="background-color: #E6E6FA;">[](/papers/HigDimen/2-code.pdf)</font>
-->
<h2 id="高维数据-https-tang-jay-github-io-highdimen"><a href="https://tang-jay.github.io/HighDimen">高维数据</a></h2>
<ul>
<li>
<p>Nordmana, D.J. and Lahiri, S.N. (2014). A review of empirical likelihood methods for time series. <em>Journal of Statistical Planning and Inference, 155</em>, 1-18.
<a href="/papers/HigDimen/1.pdf"><code>PDF</code></a>
<a href="/papers/HigDimen/1-note.pdf"><code>NOTE</code></a></p>
</li>
<li>
<p>Shi, J. (2007). Empirical likelihood for higher dimensional linear models. <em>J. Sys. Sci. &amp; Math. Scis., 27</em>, 124-133.
<a href="/papers/HigDimen/2.pdf"><code>PDF</code></a>
<a href="/papers/HigDimen/2-note.pdf"><code>NOTE</code></a></p>
<ul>
<li><a href="/papers/HigDimen/2-1.pdf">1984 Ghosh M</a></li>
<li><a href="/papers/HigDimen/2-2.pdf">2000 Shi J</a></li>
<li><a href="/papers/HigDimen/2-3.pdf">1987 de Jong P</a></li>
</ul>
</li>
<li>
<p>Chen, S.X., Peng, L. and Qin, Y.L. (2009). Effects of data dimension on empirical likelihood. <em>Biometrika, 96</em>, 711-722.
<a href="/papers/HigDimen/3.pdf"><code>PDF</code></a>
<a href="/papers/HigDimen/3-note.pdf"><code>NOTE</code></a>
<a href="https://github.com/Tang-Jay/HigDimen/tree/main/2009ChenSongxi"><code>CODE</code></a></p>
</li>
<li>
<p>Chang, J.Y., Chen, S.X. and Tang, C.Y. (2020). High-dimensional empirical likelihood inference. <em>Biometrika, 00</em>, 1-21.
<a href="/papers/HigDimen/3-1.pdf"><code>PDF</code></a></p>
</li>
<li>
<p>Chang, J.Y., Chen, S.X. and Chen, X.H. (2015). High dimensional generalized empirical likelihood for moment restrictions with dependent data. <em>Journal of Econometrics,  185</em>, 283-304.
<a href="/papers/HigDimen/3-2.pdf"><code>PDF</code></a></p>
</li>
<li>
<p>N.L. Hjort, I.W. Mckeague, I.V. Keilegom, 2009. Extending the scop of empirical likelihood. <em>The Annals of Statistics. 37</em>, 1079-1111. <a href="/papers/HigDimen/1-1.pdf"><code>PDF</code></a></p>
</li>
</ul>

        
        ]]>
      </description>
    </item>
    
    
    
    <item>
      <title>对称矩阵</title>
      <link>/cn/2022/09/22/paper/</link>
      <pubDate>Thu, 22 Sep 2022 00:00:00 +0000</pubDate>
      <author>Tan Jay</author>
      <guid>/cn/2022/09/22/paper/</guid>
      <description>
        <![CDATA[
        <blockquote>
<p>Hessian矩阵、协方差矩阵、空间权重矩阵都是对称矩阵，相关的性质有必要了解一下。</p>
</blockquote>
<hr>
<h3 id="对称矩阵">对称矩阵</h3>
<ol>
<li><a href="https://mp.weixin.qq.com/s/mTiT8wNovGGAawlO-608_w">矩阵二次型及其性质</a></li>
<li><a href="/papers/SymMatrix/%E5%AF%B9%E7%A7%B0%E7%9F%A9%E9%98%B5%E7%9A%84%E4%B8%80%E4%BA%9B%E6%80%A7%E8%B4%A8%E5%92%8C%E5%AE%9A%E7%90%86_%E9%9F%A9%E6%8C%AF%E8%8A%B3.pdf">对称矩阵的一些性质和定理_韩振芳.pdf</a></li>
<li><a href="/papers/SymMatrix/%E5%AF%B9%E7%A7%B0%E7%9F%A9%E9%98%B5%E7%9A%84%E6%80%A7%E8%B4%A8%E5%8F%8A%E5%BA%94%E7%94%A8_%E5%8F%B8%E5%87%A4%E5%A8%9F.pdf">对称矩阵的性质及应用_司凤娟.pdf</a></li>
<li><a href="/papers/SymMatrix/%E5%AF%B9%E7%A7%B0%E7%9F%A9%E9%98%B5%E6%95%99%E4%B8%8E%E5%AD%A6_%E7%8E%8B%E5%AE%8F%E5%85%B4.pdf">对称矩阵教与学_王宏兴.pdf</a></li>
</ol>
<h3 id="反对称矩阵">反对称矩阵</h3>
<ol>
<li><a href="/papers/SymMatrix/%E5%AF%B9%E7%A7%B0%E7%9F%A9%E9%98%B5%E4%B8%8E%E5%8F%8D%E5%AF%B9%E7%A7%B0%E7%9F%A9%E9%98%B5%E7%9A%84%E8%8B%A5%E5%B9%B2%E6%80%A7%E8%B4%A8_%E6%AD%A6%E7%A7%80%E7%BE%8E.pdf">对称矩阵与反对称矩阵的若干性质_武秀美.pdf</a></li>
<li><a href="/papers/SymMatrix/%E5%AF%B9%E7%A7%B0%E7%9F%A9%E9%98%B5%E5%92%8C%E5%8F%8D%E5%AF%B9%E7%A7%B0%E7%9F%A9%E9%98%B5%E7%9A%84%E8%8B%A5%E5%B9%B2%E6%80%A7%E8%B4%A8_%E9%82%B9%E6%9C%AC%E5%BC%BA.pdf">对称矩阵和反对称矩阵的若干性质_邹本强.pdf</a></li>
<li><a href="/papers/SymMatrix/%E5%85%B3%E4%BA%8E%E5%AF%B9%E7%A7%B0%E7%9F%A9%E9%98%B5%E4%B8%8E%E5%8F%8D%E5%AF%B9%E7%A7%B0%E7%9F%A9%E9%98%B5%E7%9A%84%E8%8B%A5%E5%B9%B2%E6%80%A7%E8%B4%A8_%E6%9C%B1%E4%BA%9A%E8%8C%B9.pdf">关于对称矩阵与反对称矩阵的若干性质_朱亚茹.pdf</a></li>
</ol>
<h3 id="非对称矩阵">非对称矩阵</h3>
<ol>
<li><a href="/papers/SymMatrix/%E9%9D%9E%E5%AF%B9%E7%A7%B0%E6%AD%A3%E5%AE%9A%E7%9F%A9%E9%98%B5%E7%9A%84%E6%80%A7%E8%B4%A8_%E7%8E%8B%E4%B8%96%E6%81%92.pdf">非对称正定矩阵的性质_王世恒.pdf</a></li>
</ol>
<h3 id="对称矩阵应用">对称矩阵应用</h3>
<ol>
<li><a href="/papers/SymMatrix/%E5%AE%9E%E5%AF%B9%E7%A7%B0%E7%9F%A9%E9%98%B5%E7%9A%84%E6%80%A7%E8%B4%A8%E5%8F%8A%E5%85%B6%E5%BA%94%E7%94%A8_%E8%96%9B%E5%BB%BA%E6%98%8E.pdf">实对称矩阵的性质及其应用_薛建明.pdf</a></li>
<li><a href="/papers/SymMatrix/%E5%AE%9E%E5%AF%B9%E7%A7%B0%E7%9F%A9%E9%98%B5%E7%89%B9%E5%BE%81%E5%80%BC%E7%9A%84%E6%80%A7%E8%B4%A8%E5%8F%8A%E5%85%B6%E5%BA%94%E7%94%A8_%E6%9D%A8%E5%8F%AC.pdf">实对称矩阵特征值的性质及其应用_杨召.pdf</a></li>
</ol>
<h3 id="特征向量求法">特征向量求法</h3>
<ol>
<li><a href="/papers/SymMatrix/%E8%AE%A1%E7%AE%97%E5%AE%9E%E5%AF%B9%E7%A7%B0%E7%9F%A9%E9%98%B5%E7%89%B9%E5%BE%81%E5%80%BC%E7%89%B9%E5%BE%81%E5%90%91%E9%87%8F%E7%9A%84%E5%B9%82%E6%B3%95_%E6%9B%BE%E8%8E%89.pdf">计算实对称矩阵特征值特征向量的幂法_曾莉.pdf</a></li>
<li><a href="/papers/SymMatrix/%E5%88%A9%E7%94%A8%E7%89%B9%E5%BE%81%E7%9F%A9%E9%98%B5%E6%B1%82%E5%AE%9E%E5%AF%B9%E7%A7%B0%E7%9F%A9%E9%98%B5%E7%9A%84%E7%89%B9%E5%BE%81%E5%90%91%E9%87%8F_%E5%AD%9F%E5%AE%AA%E8%90%8C.pdf">利用特征矩阵求实对称矩阵的特征向量_孟宪萌.pdf</a></li>
</ol>
<h3 id="其他特殊矩阵">其他特殊矩阵</h3>
<ol>
<li><a href="https://mp.weixin.qq.com/s/Ci8iJ1YK3-AV8xWbGMJwrw">幂等矩阵、投影矩阵和Cochran定理</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzI3NzE3NDAxMg==&amp;mid=2247490095&amp;idx=1&amp;sn=16bc42b1823fc8067270b2a4428600f0&amp;chksm=eb6b19bcdc1c90aacb507441d5b4e4fb8a72ef1ffb4f2f161c44549aad063f11ccfaef076842&amp;scene=178&amp;cur_album_id=2185022661871960071#rd">Cochran定理</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzI3NzE3NDAxMg==&amp;mid=2247484817&amp;idx=1&amp;sn=74dc04683a2da5b0282be80f0e0505dc&amp;chksm=eb6b0602dc1c8f1447ec134259af88d42f2b67c10a3fde0026d4dbf594fb7955b4420bbbfd1a&amp;cur_album_id=2185022661871960071&amp;scene=190#rd">分块矩阵及其统计学应用</a></li>
</ol>

        
        ]]>
      </description>
    </item>
    
    
    
    <item>
      <title>秦导推荐</title>
      <link>/cn/2022/09/21/paper/</link>
      <pubDate>Wed, 21 Sep 2022 00:00:00 +0000</pubDate>
      <author>Tan Jay</author>
      <guid>/cn/2022/09/21/paper/</guid>
      <description>
        <![CDATA[
        <h2 id="摘要写作">摘要写作</h2>
<ul>
<li>
<p><a href="/papers/QinRecom/Abstra-1.pdf">范文 1</a></p>
</li>
<li>
<p><a href="/papers/QinRecom/Abstra-2.pdf">范文 2</a></p>
</li>
</ul>
<h2 id="空间数据">空间数据</h2>
<ul>
<li>
<p>秦永松 <a href="/papers/QinRecom/Qin-2.pdf"><code>空间计量经济模型的经验似然研究进展</code></a></p>
</li>
<li>
<p>Baltagi, B. H., Song, S. H., and Won K. (2003). Testing panel data regression models with spatial error correlation. <em>Journal of Econometrics, 117</em>, 123-150. <a href="/papers/QinRecom/Recom-1.pdf"><code>PDF</code></a></p>
</li>
<li>
<p>Baltagi, B. H. (2021). <em>Econometric Analysis of Panel Data</em>. Springer Cham. <a href="/papers/QinRecom/Recom-2.pdf"><code>PDF</code></a></p>
</li>
</ul>
<h2 id="经济类">经济类</h2>
<p>来自<a href="www.must.edu.mo/cn/msb/staff">澳门科技大学老师主页</a>。</p>
<ul>
<li><a href="/papers/QinRecom/Lin-1.pdf"><code>PDF1</code></a></li>
<li><a href="/papers/QinRecom/Lin-2.pdf"><code>PDF2</code></a></li>
<li><a href="/papers/QinRecom/Lin-3.pdf"><code>PDF3</code></a></li>
<li><a href="/papers/QinRecom/Lin-4.pdf"><code>PDF4</code></a></li>
<li><a href="/papers/QinRecom/Lin-5.pdf"><code>PDF5</code></a></li>
<li><a href="/papers/QinRecom/Lin-6.pdf"><code>PDF6</code></a></li>
</ul>
<!--
## 老师原稿
- [统计模拟和实证介绍](/papers/QinRecom/Qin-1.pdf) [`CODE`](/papers/QinRecom/Qin-1-code.R)
-->

        
        ]]>
      </description>
    </item>
    
    
    
    <item>
      <title>Bookdown&#43;GitHub发布电子书</title>
      <link>/cn/2022/09/15/bookdown/</link>
      <pubDate>Thu, 15 Sep 2022 00:00:00 +0000</pubDate>
      <author>Tan Jay</author>
      <guid>/cn/2022/09/15/bookdown/</guid>
      <description>
        <![CDATA[
        <p>这是Bookdown的小试牛刀，写一本自己免费出版的电子书。以一篇听课<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>笔记为例，我的电子笔记见<a href="https://tang-jay.github.io/EssayNotes/">《论文写作听课笔记》</a>。</p>
<p>之所以想做这件事情，是因为在<a href="https://tang-jay.github.io/cn/2022/08/02/yihui/">8月2日</a>，无意看到大佬们发布的电子书，有章节有插图有公式，这可以很好地整理日常零碎的知识，并便于查阅，非常心动。他们的电子书如下所示：</p>
<ul>
<li><a href="https://www.math.pku.edu.cn/teachers/lidf/docs/Rbook/html/_Rbook">R语言教程</a></li>
<li><a href="https://wxhyihuan.github.io/MedicalStatisNotes/">医学统计笔记与R语言</a></li>
<li><a href="https://tangyc8866.github.io/bookdown_tutorial/">Bookdown中文书稿写作手册</a></li>
<li><a href="http://gisersqdai.top/Note-of-Applied-Statistics-with-R-Book/">应用统计学与R语言实现学习笔记</a></li>
</ul>
<p>🤔我觉得更多的好处在于，费一点时间学会之后，后期的增益是很快的，可以更专注于写作和思考。比如，R可以绘制许多漂亮的图形，程序运行之后，代码不能按照某种逻辑串联起来（又乱），或是存储在本地内存的时间久了可能被清除掉（又难找）。数学有许多推导，若是我早一些知道这些工具，我就可以更好地整理出来方便自己复习巩固。工欲善其事必先利其器，有了更好的工具确实让人有更求好的心。</p>
<p>网上有<a href="https://www.math.pku.edu.cn/teachers/lidf/docs/Rbook/html/_Rbook/bookdown.html">Bookdown</a>教程<sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup>，没有将bookdouwn写好的电子书发布到GitHub的教程，我把教程写<a href="https://blog.csdn.net/JTang1995/article/details/126876006">这里</a>。</p>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>网站：<em>深度之眼</em>。<a href="https://ai.deepshare.net/detail/p_5f3a40dae4b011878731630e/6">论文指导系列课程</a>&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2">
<p>网站：<em>科学网</em>。<a href="https://blog.sciencenet.cn/blog-3247241-1277275.html">应用统计学与R语言实现笔记（番外篇四）bookdown使用与OR值计算</a>&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>

        
        ]]>
      </description>
    </item>
    
    
    
    <item>
      <title>如何写好学术论文</title>
      <link>/cn/2022/09/11/note/</link>
      <pubDate>Sun, 11 Sep 2022 00:00:00 +0000</pubDate>
      <author>Tan Jay</author>
      <guid>/cn/2022/09/11/note/</guid>
      <description>
        <![CDATA[
        <blockquote>
<p>对自己要求不高，在进步就行，在慢慢的过程里，将事情逐渐办得精益求精。</p>
</blockquote>
<hr>
<p>这是一篇论文写作笔记<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup><sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup>，全篇以AI为例。论文写作的分为四个顺序：阅读论文→确定创新点→实验→论文写作。</p>
<h3 id="阅读论文">阅读论文</h3>
<p>发表论文的前提是大量阅读论文，文献阅读分为三个阶段，初期找方向，中期重点突破，后期广泛涉猎。</p>
<p>初期读论文需要逐字精读，感兴趣的论文都可以去读。一篇论文用时一天。前期阅读论文数量30篇以上，可以提高学术英语阅读能力和专业术语积累。</p>
<p>中期读论文要重点精读，限定研究方向。重点论文时间控制在半天，泛泛论文是一小时。重点论文须重复读及源码学习。论文阅读数最好为10篇以上，了解学习技术演进、学习方法创新和整理创新方法链。</p>
<p>后期少数精读+大量泛读，不限定方向，自己重点方向+涉猎方向。
重点论文两小时，泛泛论文半小时，跟随研究方向的最新发展，了解其他方向的大致进展，思考创新点引进嫁接。</p>
<h3 id="确定创新点">确定创新点</h3>
<p>可以从以下四个方面确定自己论文的创新点：</p>
<ol>
<li>数据集的改动：噪声、几何变换、遮挡、光照条件、场景依赖</li>
<li>模型的问题：模型体积、推理速度、收敛困难、非端到端、后处理优化</li>
<li>结构替换：transformer、FCN、AE、</li>
<li>特定场景的应用：通用模型考虑泛化能力—特定应用考虑专用性。比如夜间检测、水下检测、鱼眼相机检测。</li>
</ol>
<p>另外就是要记住A+B+C/2.5法则</p>
<p>A：本研究方向的继承性创新点（自然演进）<br>
B：其他方向的既有方法（嫁接到其他任务）<br>
C：细节上的创新（数据增强/数据集/损失函数设计）</p>
<h3 id="实验">实验</h3>
<ol>
<li>找到baseline论文的代码；</li>
<li>在baseline代码上实现期望功能的最小化实现；</li>
<li>逐步实现最终的功能代码，同时做实现验证各部分设计的效果。</li>
</ol>
<h3 id="论文写作">论文写作</h3>
<p><strong>01 写作策略</strong></p>
<p>选择2篇左右的范文，去分析论文结构（Introduction）、重点词句（Related Work）、语言风格（Method）、实验设计（Experiment）、绘图风格（Conclusion）和故事设计（References）。</p>
<p><strong>02 论文写作技巧</strong></p>
<ul>
<li>
<p>注意标题</p>
<ul>
<li>用⼀句话概括你所做的工作</li>
<li>考虑搜索引擎的影响，包含关键词</li>
<li>可以新颖一些</li>
</ul>
</li>
<li>
<p>首页加图</p>
</li>
<li>
<p>Introduction直接列贡献</p>
<ul>
<li>不用介绍各个部分如何组织的；</li>
<li>直接说做出了哪些贡献；</li>
<li>标明贡献位置。</li>
</ul>
</li>
</ul>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>公众号：<em>计算机视觉联盟</em>。<a href="https://mp.weixin.qq.com/s/-NSWNppMVb3h8itldYhrtA">审稿人：如何写好一篇学术论文?!</a>&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2">
<p>网站：<em>深度之眼</em>。<a href="https://ai.deepshare.net/detail/p_5f3a40dae4b011878731630e/6">论文指导系列课程</a>&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>

        
        ]]>
      </description>
    </item>
    
    
    
    <item>
      <title>刘润语录</title>
      <link>/cn/2022/09/06/liurun/</link>
      <pubDate>Tue, 06 Sep 2022 00:00:00 +0000</pubDate>
      <author>Tan Jay</author>
      <guid>/cn/2022/09/06/liurun/</guid>
      <description>
        <![CDATA[
        <ol>
<li>开挂的人生，有<a href="https://mp.weixin.qq.com/s/InWLfSVS1l_d0uz9r7by6w">三条路</a>，体育生（靠努力），数学生（靠脑力）和艺术生（靠技能）。</li>
</ol>
<blockquote>
<p>看完文章才懂得，自己学的数学走的体育生的路，哈哈。不过我觉得体育生是基础，可以体育生+数学生，体育生+艺术生，体育生+数学生+艺术生～  如果可以选的话🤔，我的心告诉我，我更倾向于艺术生，自由、偏执、自我。我愿意让自己尝试做任何事情，不擅长的，无用的，但是要做的话，我都会沉浸体验，认真做，至少像那么回事（理想是这样），从过程中获得满足感。</p>
</blockquote>
<ol start="2">
<li>如何摆脱过早在低层次形成<a href="https://mp.weixin.qq.com/s/1Wgk7HOzRxuk4mjhFFizlw">认知闭环</a>？首先我们通过看书扩大自己的认知闭环，然后，通过走出去检验自己的认知闭环，比如，多见人、多看、多听。</li>
</ol>
<blockquote>
<p>原文说：“我们生活在固有认知的高墙里，书就是用来凿壁偷光的。” 一下子对小时候学的课文《凿壁借光》有了新的理解，这个‘光’，有看得见的光，煤油光，有看不见的光，知识的光。看得见的光穿过墙壁照在课本上，看不见的光透过心墙照进心田。小时候只是觉得，这个人真努力，那么艰苦也要为学习创造条件，那我们有日光灯，应该珍惜呀。现在觉得，这个人是受那个突破自我边界的光深深的吸引，古之贤者在书中与他会晤，告诉他，人穷志不能穷，告诉他，达则兼济天下，穷则独善其身，等等，等等。</p>
</blockquote>

        
        ]]>
      </description>
    </item>
    
    
    
    <item>
      <title>成甲语录</title>
      <link>/cn/2022/09/04/note/</link>
      <pubDate>Sun, 04 Sep 2022 00:00:00 +0000</pubDate>
      <author>Tan Jay</author>
      <guid>/cn/2022/09/04/note/</guid>
      <description>
        <![CDATA[
        <p>原文<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>讲述了一个学习公式，学习 <code>$=$</code> 改变，改变 <code>$=$</code> 尝试 <code>$\times$</code> 反思 <code>$\times$</code> 对标 <code>$\times$</code> 圈子。文章写得挺有好👍，奈何吸收不了🤦‍♀️，那就挑喜欢的抄一下吧✌️。</p>
<ol>
<li>
<p>努力做一个快乐的、无知无畏的、对世界充满好奇的小学生。</p>
</li>
<li>
<p>理想主义者不要求环境是完全理想的，但理想主义者不放弃，对于理想的追求。</p>
</li>
</ol>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>公众号：<em>特别关注</em>。<a href="https://mp.weixin.qq.com/s/ZiZbYQlCbMYNsfYNGWSvpg">学习，没有捷径</a>&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>

        
        ]]>
      </description>
    </item>
    
    
    
    <item>
      <title>Borel-Cantelli引理</title>
      <link>/cn/2022/09/03/borel-cantelli/</link>
      <pubDate>Sat, 03 Sep 2022 00:00:00 +0000</pubDate>
      <author>Tan Jay</author>
      <guid>/cn/2022/09/03/borel-cantelli/</guid>
      <description>
        <![CDATA[
        <p>这是一篇摘记<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>。</p>
<h2 id="引理作用">引理作用</h2>
<p>Borel-Cantelli引理是概率论中一个很重要的引理。该引理可以帮忙我们理解<strong>几乎处处收敛</strong>和<strong>依概率收敛</strong>之间的关系，也可用于论证强相合性和强大数律等。为说明该引理，法国数学家博雷尔(Émile Borel, 1871-1956)在1913年介绍了“打字的猴子”的概念。无限猴子定理指出，一个在打字机键盘上随机敲打键盘的猴子，只要时间无限长，那么它几乎肯定会键入任何给定的文本，例如莎士比亚全集。</p>
<h2 id="引理由来">引理由来</h2>
<p><strong>定义1</strong> <code>$\quad$</code> 设<code>$\{X_n,n \ge 1\}$</code> 是随机变量序列，若存在随机变量<code>$X$</code>使得
$$Pr\left(\omega \in \Omega: \lim_{n \to \infty} X_n(\omega)=X(\omega)\right)=1,$$
则称随机变量序列<code>$\{X_n,n \ge 1\}$</code>几乎必然收敛（或以概率1收敛）于<code>$X$</code>，记为<code>$X_n \to X, a.s.$</code>。</p>
<p><strong>定义2</strong> <code>$\quad$</code> 设<code>$\{X_n,n \ge 1\}$</code> 是随机变量序列，若存在随机变量<code>$X$</code>使得对任意的<code>$\epsilon &gt; 0$</code>，有
$$\lim_{n \to \infty} Pr(|X_n-X|\ge\epsilon)=0,$$
则称随机变量序列<code>$\{X_n,n \ge 1\}$</code>依概率收敛于<code>$X$</code>， 记为<code>$X_n \stackrel{p}{\longrightarrow} X$</code>。</p>
<p><strong>定理1</strong> <code>$\quad$</code> <code>$X_n \implies X, a.s.$</code> 等价于<code>$\forall \epsilon &gt; 0$</code>，
$$Pr(|X_n-X|&gt;\epsilon \ i.o.) = \lim_{n \to \infty}Pr(\bigcup_{k=n}^{\infty}|X_n-X|&gt;\epsilon)=0。$$</p>
<p><strong>总结</strong> <code>$\quad$</code> 几乎处处收敛考察的是不收敛的样本点的概率是否为 0，而依概率收敛则考察<code>$X_n$</code>和<code>$X$</code>差异的尾概率是否趋于 0。定理1给出几乎处处收敛的等价定义，可知，几乎处处收敛<code>$\implies$</code>依概率收敛。那么在什么条件下，依概率收敛<code>$\implies$</code>几乎处处收敛呢？对此，Borel-Cantelli第一引理给出了答案。</p>
<h2 id="引理内容">引理内容</h2>
<p><strong>引理1</strong> <code>$\quad$</code> 设<code>$\{A_n, n=1,2,\cdots\}$</code>是一列事件，若<code>$\sum_{n=1}^{\infty}Pr(A_n)&lt;\infty$</code>，则<code>$Pr(A_n,i.o)=0 $</code>。</p>
<p>令<code>$A_n=\{|X_n-X|&gt;\epsilon\}$</code>，则可知依概率收敛仅要求级数的每一项<code>$Pr(A_n)$</code>趋于0。而几乎处处收敛要求更高一点，需要对应的级数是收敛的(充分条件)，这就要求级数的每一项<code>$Pr(A_n)$</code>趋于0的速度要快一点。</p>
<p><strong>引理1推论</strong> <code>$\quad$</code> 依概率收敛可以推出子列几乎处处收敛。</p>
<p><strong>引理2</strong> <code>$\quad$</code> 设<code>$\{A_n, n=1,2,\cdots\}$</code>是独立的事件列，若<code>$\sum_{n=1}^{\infty}Pr(A_n)=\infty$</code>，则<code>$Pr(A_n,i.o)=1 $</code>。</p>
<p>下面给出一个简单的例子予以说明引理2。假设我们抛掷一个骰子无穷多次，那么骰子正面出现数值6无穷多次的概率是多少？答案是1。实际上令<code>$A_n$</code>表示第<code>$n$</code>次抛掷出现6，容易知道<code>$Pr(A_n)=1/6$</code>，而且<code>$\{A_n,\ge 1\}$</code>之间相互独立，从而<code>$\sum_{n=1}^{\infty}Pr(A_n)=\sum_{n=1}^{\infty}1/6=\infty$</code>，因此，<code>$A_n$</code>发生无穷多次的概率是1。换而言之，只要某一事件可能发生，即使发生的概率非常非常小，同时不同事件相互独立，则该事件在无限长时间内几乎必然发生。</p>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>公众号：<em>郭老师统计小课堂</em>。 <a href="https://mp.weixin.qq.com/s/XyfP9-ZTr_rb9CufIwkCDA">Borel-Cantelli引理</a>&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>

        
        ]]>
      </description>
    </item>
    
    
    
    <item>
      <title>《手把手教你雅思写作剑12》</title>
      <link>/cn/2022/09/02/writing/</link>
      <pubDate>Fri, 02 Sep 2022 00:00:00 +0000</pubDate>
      <author>Tan Jay</author>
      <guid>/cn/2022/09/02/writing/</guid>
      <description>
        <![CDATA[
        <h2 id="雅思写作主要学习方法">雅思写作主要学习方法</h2>
<h3 id="如何做句子翻译练习来更好地提升写作能力">如何做句子翻译练习来更好地提升写作能力</h3>
<ol>
<li>英文地道，拒绝中式英语。</li>
<li>英文能在书面和口语交流中用到。</li>
<li>句子翻译，即中文到English，翻译过程中，词伙的使用和句子结构的掌握是关键。</li>
</ol>
<h3 id="翻译">翻译</h3>
<p>翻译遵循的步骤：</p>
<blockquote>
<p>第一步，思考词伙；</p>
</blockquote>
<blockquote>
<p>第二步，找<a href="/cn/2022/09/02/cihuo/">词伙</a>，查看答案用的什么词伙；</p>
</blockquote>
<blockquote>
<p>第三步，用什么<a href="/cn/2022/09/02/sentence/">句子结构</a>；</p>
</blockquote>
<blockquote>
<p>第四步，如果句子写错了，要看自己<a href="/cn/2022/09/02/error/">错在哪里</a>。</p>
</blockquote>
<p>翻译的基础：</p>
<blockquote>
<p>词性</p>
</blockquote>
<blockquote>
<p>简单句</p>
</blockquote>
<blockquote>
<p>复杂句</p>
</blockquote>

        
        ]]>
      </description>
    </item>
    
    
    
    <item>
      <title>句子结构</title>
      <link>/cn/2022/09/02/sentence/</link>
      <pubDate>Fri, 02 Sep 2022 00:00:00 +0000</pubDate>
      <author>Tan Jay</author>
      <guid>/cn/2022/09/02/sentence/</guid>
      <description>
        <![CDATA[
        <h2 id="判别句子结构">判别句子结构</h2>
<ol>
<li>
<p>&ldquo;是个&rdquo; <code>$ \implies $</code> 主系表</p>
</li>
<li>
<p>&ldquo;以<code>$ \cdots $</code> 而出名&rdquo; <code>$ \implies $</code> 主系表 are famous / well-known for</p>
</li>
</ol>
<blockquote>
<p>famous as 作为什么而出名 ❌</p>
</blockquote>
<ol>
<li>
<p>&ldquo;一直在&rdquo; <code>$ \implies $</code> 主系表 has been</p>
</li>
<li>
<p>&ldquo;已经成为&rdquo; <code>$ \implies $</code> 主系表 has become</p>
</li>
</ol>

        
        ]]>
      </description>
    </item>
    
    
    
    <item>
      <title>总结错误</title>
      <link>/cn/2022/09/02/error/</link>
      <pubDate>Fri, 02 Sep 2022 00:00:00 +0000</pubDate>
      <author>Tan Jay</author>
      <guid>/cn/2022/09/02/error/</guid>
      <description>
        <![CDATA[
        <h2 id="错过的地方">错过的地方</h2>
<ol>
<li>一些国家的人如果犯罪会面临长期服刑。<br>
People in some countries <strong>have to</strong> face <strong>a long prison term</strong> if they <strong>commit crimes</strong>.</li>
</ol>

        
        ]]>
      </description>
    </item>
    
    
    
    <item>
      <title>词伙</title>
      <link>/cn/2022/09/02/cihuo/</link>
      <pubDate>Fri, 02 Sep 2022 00:00:00 +0000</pubDate>
      <author>Tan Jay</author>
      <guid>/cn/2022/09/02/cihuo/</guid>
      <description>
        <![CDATA[
        <p>词伙字典，<a href="https://mp.weixin.qq.com/s/D2JxLIiNUubRsy4f0el7-w">教程</a>，<a href="https://pan.baidu.com/s/1HLrOoATaYFQhMcvGB7rgLg?pwd=j5b2">下载</a>。</p>
<h1 id="积累词伙">积累词伙</h1>
<h2 id="名词性短语">名词性短语</h2>
<p>学费 = tuition fee</p>
<p>旅游旺季 = tourist season</p>
<p>交通噪声 = traffic noise</p>
<p>很大的问题 = a serious / severe problem</p>
<p>丰富的历史 = rich history</p>
<p>历史的 / 壮观的建筑 = historical / spectacular / monumental / ancient buildings</p>
<p>没有错误的句子 = error-free sentences</p>
<p>汽车和飞机的尾气 = the emissions from vehicles and planes</p>
<blockquote>
<p>冠词 + 名词 + 介宾短语</p>
</blockquote>
<p>相互交流的机会 = opportunities to communicate with each other</p>
<p>惯例 = the norm</p>
<p>有限的职位 = limited positions</p>
<blockquote>
<p>相关词汇 ： 应聘者 job applicants</p>
</blockquote>
<p>积累财富 = accumulate wealth</p>
<p>幸福繁荣的社会 = happy and prosperous society</p>
<p>生活拮据的人 = those who live on a tight budget</p>
<p>减税 = tax reductions</p>
<h3 id="法律词汇">法律词汇</h3>
<p>犯罪 = commit crimes</p>
<p>长期服刑 = a long prison term</p>
<p>重犯 = serious offenders</p>
<p>送到监狱 = sent to prison</p>
<p>减少犯罪 = deter crime</p>
<h2 id="动词性短语">动词性短语</h2>
<p>对（做什么的人）有好处 = are beneficial to those who do sth.</p>

        
        ]]>
      </description>
    </item>
    
    
    
    <item>
      <title>雅思</title>
      <link>/cn/2022/09/01/ielts/</link>
      <pubDate>Thu, 01 Sep 2022 00:00:00 +0000</pubDate>
      <author>Tan Jay</author>
      <guid>/cn/2022/09/01/ielts/</guid>
      <description>
        <![CDATA[
        <blockquote>
<p>2022年的暑假学习写英文论文，秦老师很耐心地批改我难以言喻的中式英语，真的感谢我的老师，没有批评我一句，为此，我更希望全方位提高自己英语水平，莫给老师添负担。</p>
</blockquote>
<hr>
<h2 id="听">听</h2>
<h2 id="说">说</h2>
<h2 id="读">读</h2>
<h2 id="写">写</h2>
<ol>
<li><a href="/cn/2022/09/02/writing">《手把手雅思写作剑12》顾家北</a></li>
</ol>
<h2 id="资源">资源</h2>
<ol>
<li>
<p><a href="https://zhuanlan.zhihu.com/p/265752658">雅思最全学习网站</a></p>
</li>
<li>
<p>IELTS MATERIAL.</p>
<ul>
<li>网站地址：<a href="http://ieltsmaterial.com/">http://ieltsmaterial.com/</a></li>
<li>网站介绍：这里拥有非常全的雅思学习资料，主要包含了雅思课程、备考书籍、高分备考词汇表、写作高分范文、模拟试题、备考建议等等。</li>
</ul>
</li>
<li>
<p>IELTS Buddy</p>
<ul>
<li>网站地址：<a href="http://www.ieltsbuddy.com/">http://www.ieltsbuddy.com/</a></li>
<li>网站介绍：这里划分非常的详细，针对听说读写、词汇和语法都有相应的练习和技巧。</li>
</ul>
</li>
<li>
<p>IELTS FOR FREE</p>
<ul>
<li>网站地址：<a href="https://ieltsforfree.com/">https://ieltsforfree.com/</a></li>
<li>网站介绍：适用于A类和G类考生，并且网站有一亮点就是可以查看自己观看的课程记录，便于查找和反复消化。</li>
</ul>
</li>
<li>
<p>Simon官网</p>
<ul>
<li>网站地址：<a href="http://ielts-simon.com/">http://ielts-simon.com/</a></li>
<li>网站介绍：Simon作为英国曼城的前雅思考官，对雅思备考技巧自然有专业的解读，所以很值得学习，尤其是他写的雅思范文很值得精读！</li>
</ul>
</li>
<li>
<p>Ryan&rsquo;s IELTS Blog</p>
<ul>
<li>网站地址：<a href="http://ieltsielts.com/earlier-blog-posts/">http://ieltsielts.com/earlier-blog-posts/</a></li>
<li>网站介绍：听说读写备考建议+学生作文批改服务。</li>
</ul>
</li>
<li>
<p>The IELTS Network</p>
<ul>
<li>网站地址：<a href="http://www.ieltsnetwork.com/">http://www.ieltsnetwork.com/</a></li>
<li>网站介绍：上面有很多帖子都是大家组团口语Partner的，有skype group和whatsapp group可供大家选择组团联系口语，还可以认识更多世界各国的小伙伴。</li>
</ul>
</li>
<li>
<p>IELTS Advantage</p>
<ul>
<li>网站地址：<a href="https://www.ieltsadvantage.com/">https://www.ieltsadvantage.com/</a></li>
<li>网站介绍：基本的雅思高分套路。听说读写免费资料+写作口语增值服务。</li>
</ul>
</li>
<li>
<p>10IELTS LIZ</p>
<ul>
<li>网站地址：<a href="http://ieltsliz.com/">http://ieltsliz.com/</a></li>
<li>网站介绍：雅思考试技巧，听说读写练习，写作高分范文。</li>
</ul>
</li>
</ol>

        
        ]]>
      </description>
    </item>
    
    
    
    <item>
      <title>刘润对谈吴军</title>
      <link>/cn/2022/08/11/note/</link>
      <pubDate>Thu, 11 Aug 2022 00:00:00 +0000</pubDate>
      <author>Tan Jay</author>
      <guid>/cn/2022/08/11/note/</guid>
      <description>
        <![CDATA[
        <h2 id="笔记">笔记</h2>
<p>这是一篇个人笔记，对照原文去掉了着重标识。</p>
<p>原文可参见<a href="https://mp.weixin.qq.com/s/qzi-iirrLKEumvvNGKe2Sg">《刘润对谈吴军：每个人都一定要有数学思维》</a>。</p>
<p><img src="/images/talk.jpeg" alt="Liu talk with Wu"></p>
<p>具体来说，数学思维包括哪些呢？下面介绍<code>$5$</code>种。</p>
<hr>
<h2 id="数学思维一-从不确定性中找到确定性">数学思维一：从不确定性中找到确定性</h2>
<p>第一种数学思维，源自于概率论，叫做从不确定性中找到确定性。</p>
<p>什么意思？</p>
<p>假如一件事情成功的概率是<code>$20\%$</code>，是不是就意味着，我重复做这件事<code>$5$</code>次，就一定能成功呢？</p>
<p>很多人会这样想，但事实并不是这样。</p>
<p>如果我们把<code>$95\%$</code>的概率定义为成功，那么这件<code>$20\%$</code>成功概率的事，你需要重复做<code>$14$</code>次。</p>
<p>换句话说，你只要把这件<code>$20\%$</code>成功概率的事，重复做<code>$14$</code>次，你就有<code>$95\%$</code>的概率能做成。</p>
<blockquote>
<p>计算过程:</p>
<p>做一次失败的概率为：<code>$ 1-20\%=80\%=0.8 $</code></p>
<p>重复做<code>$n$</code>次至少有一次成功的概率是<code>$95\%$</code>，就相当于重复做<code>$n$</code>次每一次都不成功的概率是<code>$5\%$</code>，</p>
<p>重复做<code>$n$</code>次都不成功 <code>$0.8^n =1- 95\% = 5\% $</code></p>
<p><code>$$  n=\log(0.8,0.05)=13.42 $$</code></p>
<p>所以重复做<code>$13.42$</code>次，你成功的概率能达到<code>$95\%$</code>。</p>
</blockquote>
<p>如果你要达到<code>$99\%$</code>的成功概率，那么你需要重复做21次。</p>
<p>那想达到<code>$100\% $</code>的成功概率呢？</p>
<p>对不起，这个世界上没有<code>$100\%$</code>的概率，所有人想要做成事，都需要一点点运气。</p>
<p>我们经常说，<a href="/cn/2022/07/13/tutor/">正确的事情，要重复做。</a></p>
<p>它其实就是概率论的自然语言表述。</p>
<p>所谓正确的事情，其实指的就是大概率能成功的事情。</p>
<p>而所谓的重复，学会了概率论，我们就对重复这件事有了定量的理解。</p>
<p>相对应地，很多人都想过，假如我在一个领域成功的概率是<code>$1\%$</code>，那么我找到<code>$20$</code>个领域来做，是不是跟一个领域<code>$20\%$</code>的效果是一样的？</p>
<p>如果我们依然把<code>$95\%$</code>定为成功的标准，那么<code>$1\%$</code>成功概率的事情，你需要重复做<code>$298$</code>次。</p>
<p>而这，还只是一个领域。</p>
<p>这就像很多人会问，我是成为一个全才，把<code>$20$</code>个领域都试个遍，更容易成功？</p>
<p>还是成为一个专才，在一个领域深耕，更容易成功呢？</p>
<p>概率论会告诉你，成为一个专才，成功的可能性更大。</p>
<p>理解了这件事情，你就会明白，创业要专注，不要做太多事，做太多事，你本来<code>$20\%$</code>的概率就只剩1%了，你成功的概率就会更小。</p>
<p>你看，虽然这个世界上没有<code>$100\%$</code>的概率，但是只要重复做大概率成功的事情，你成功的概率就能够接近<code>$100\%$</code>。</p>
<p>这就叫从不确定性中找到确定性。</p>
<p>这是概率论教会我们最重要的思维。</p>
<p>我们学习概率论，不是为了去算题，而是要理解这种思考方法，在做人生选择的时候，就能选对那条大概率成功的道路。</p>
<h2 id="数学思维二-用动态的眼光看问题">数学思维二：用动态的眼光看问题</h2>
<p>第二种数学思维，源自于微积分，叫做用动态的眼光看问题。</p>
<p>很多人一听说微积分，想到那些复杂的微分方程、积分方程，就头疼。</p>
<p>别怕。</p>
<p>我们今天不谈方程，只谈微积分的思维方式。</p>
<p>微积分的思维方式其实特别简单，也正因为简单到极致，所以非常漂亮。</p>
<p>微积分是牛顿发明的。他为什么要发明微积分呢？</p>
<p>是为了虐死后世的我们吗？</p>
<p>当然不是。</p>
<p>其实在牛顿以前，人们对速度这些变量的了解，仅限于平均值的层面。</p>
<p>比如，我知道一段距离的长短，和走完这段距离的时间，就可以算出一个平均速度。</p>
<p>但是，每个瞬间的速度，我是不了解的。</p>
<p>于是，牛顿就发明了微分，用无穷小这种概念来帮助我们把握瞬间的规律。</p>
<p>而积分跟微分正好相反，它反应的是瞬间变量的积累效应。</p>
<p>那么，到底什么是微积分？</p>
<p>我举个简单的例子。</p>
<p>一个物体静止不动，你推它一把，会瞬间产生一个加速度。</p>
<p>但有了加速度，并不会瞬间产生速度。</p>
<p>加速度累积一段时间，才会有速度。</p>
<p>而有了速度，并不会瞬间产生位移。</p>
<p>速度累积一段时间，才会有位移。</p>
<p>宏观上，我们看到的是位移，但是从最微观的角度来看，其实是从加速度开始的。</p>
<p>加速度累积，变成速度；速度累积，变成位移。</p>
<p>这，就是积分。</p>
<p>反过来说，物体之所以会有位移，是因为速度在一段时间的累积。</p>
<p>而物体之所以会有速度，是因为加速度在一段时间的累积。</p>
<p>位移（相对于时间）的一阶导数，是速度。</p>
<p>而速度（相对于时间）的一阶导数，是加速度。</p>
<p>宏观上，我们看到的是位移，但是从微观上来看，其实是每一个瞬间速度的累积。</p>
<p>而位移的导数，就是从宏观回到微观，去观察它“瞬间”的速度。</p>
<p>这，就是微分。</p>
<p>那么，微积分对我们的日常生活到底有什么用呢？</p>
<p>理解了微积分，你看问题的眼光，就会从静态变为动态。</p>
<p>什么意思？</p>
<p>加速度累积，变成速度；速度累积，变成位移。</p>
<p>其实人也是一样。</p>
<p>你今天晚上努力学习了，但是一晚上的努力，并不会直接变成你的能力。</p>
<p>你的努力，得累积一段时间，才会变成你的能力。</p>
<p>而你有了能力，并不会马上做出成绩。</p>
<p>你的能力，得累积一段时间，才会变成你的成绩。</p>
<p>而你有了一次成绩，并不会马上得到领导的赏识。</p>
<p>你的成绩，得累积一段时间，才会得到领导赏识。</p>
<p>从努力，到能力，到成绩，到赏识，它是有一个过程的，有一个积分的效应。</p>
<p>但是你会发现，生活中有很多人，在开始努力的第一天，就会抱怨说，我今天这么努力，领导为什么不赏识我？</p>
<p>他忘了，这其实还需要一个积分的效应。</p>
<p>反过来说，有些人可能一直以来工作都做得很好，但是从某个时候开始，因为一些原因，慢慢懈怠了。</p>
<p>他的努力程度下降了，但这个时候，他的能力并不会马上跟着下降。</p>
<p>可能过了三四个月，才会慢慢显示出来。他会发现做事情开始不能得心应手了。</p>
<p>然后又过了三四个月，他做出来的东西，领导开始越来越看不上了。</p>
<p>在这一瞬间，很多人会觉得，有什么大不了的，我不过就是这一件事没做好呗。</p>
<p>但他忘了，这其实是一个积分效应，这样的结果，其实早在七八个月前他不努力的时候，就埋下了种子。</p>
<p>努力的时候，都希望大家瞬间认可；而出了问题，却不去想几个月之前的懈怠。</p>
<p>这是很多人都容易走进的思维误区。</p>
<p>而如果你理解了微积分的思维方式，能够用动态的眼光来看问题，你就会慢慢体会到，努力需要很长时间才会得到认可，你就会拥有一个平衡的心态，就会避免犯这样的错误。</p>
<p>吴军老师经常讲一句话，叫做莫欺少年穷。</p>
<p>其实，从本质上来说，这也是微积分的思维方式。</p>
<p>少年虽穷，虽然他目前积累的还很少，但是，只要他的增速（用数学的语言来说，叫导速度）够快，经过五年十年，他的积累会非常高。</p>
<p>吴军老师给年轻人提建议说，不要在乎你的第一份薪水。</p>
<p>这其实这也是微积分的思维方式。</p>
<p>一开始拿多少钱不重要，重要的是增速（导数）。</p>
<p>微积分的思维方式，从本质上来说，就是用动态的眼光看问题。</p>
<p>一件事情的结果，并不是瞬间产生的，而是长期以来的积累效应。</p>
<p>出了问题，不要只看当时那个瞬间，你只有从宏观，一直追溯（求导）到微观，才能找到最根源的问题所在。</p>
<h2 id="数学思维三-公理体系">数学思维三：公理体系</h2>
<p>第三种数学思维，源自于几何学，叫做公理体系。</p>
<p>什么是公理体系？</p>
<p>比如，几何学有一门分科，叫做欧几里得几何，也被称为欧氏几何。</p>
<p>欧氏几何有5条最基本的公理：</p>
<blockquote>
<p>1、任意两个点可以通过一条直线连接。</p>
<p>2、任意线段能无限延长成一条直线。</p>
<p>3、给定任意线段，可以以其一个端点作为圆心，该线段作为半径作一个圆。</p>
<p>4、所有直角都全等。</p>
<p>5、若两条直线都与第三条直线相交，并且在同一边的内角之和小于两个直角和，则这两条直线在这一边必定相交。</p>
</blockquote>
<p>公理，是具有自明性并且被公认的命题。</p>
<p>在欧氏几何中，其他所有的定理（或者说命题），都是以这5条公理为出发点，利用纯逻辑推理的方法推导出来的。</p>
<p>从这5条公理出发，可以推导出无数条定理。</p>
<p>比如：</p>
<p>每一条线的角度都是180度。</p>
<p>三角形的内角和等于180度。</p>
<p>过直线外的一点，有且只有的一条直线和已知直线平行。</p>
<p>……</p>
<p>这构成了欧氏几何庞大的公理体系。</p>
<p>如果说公理体系是一棵大树，那么公理就是大树的树根。</p>
<p>而在几何学的另一门分科，罗巴切夫斯基几何中，它的公理体系又不一样了。</p>
<p>从罗巴切夫斯基几何的公理出发，可以推导出这样的定理：</p>
<p>三角形的内角和小于180度。</p>
<p>过直线外的一点，至少有两条直线和已知直线平行。</p>
<p>这跟欧氏几何是完全不同的。</p>
<p>（罗巴切夫斯基几何虽然看上去好像违反常识，但它其实解决的主要是曲面上的几何问题，跟欧氏几何并不冲突。）</p>
<p>因为公理不同，所以能推导出来的定理就不同，因此罗巴切夫斯基几何的公理体系，跟欧氏几何的公理体系，也完全不同。</p>
<p>在几何学中，一旦制定了不同的公理，就会得到完全不同的知识体系。</p>
<p>这就是公理体系的思维。</p>
<p>这种思维在我们的生活中非常重要。</p>
<p>比如，每家公司都有自己的愿景、使命、价值观，或者你也可以把它们称为公司基因或者文化。</p>
<p>因为愿景、使命、价值观不同，公司与公司之间的行为和决策，差异就会很大。</p>
<p>一家公司的愿景、使命、价值观，其实就相当于这家公司的公理。</p>
<p>公理直接决定了这家公司的各种行为往哪个方向发展。</p>
<p>所有的规章制度、工作流程、决策行为，都是在愿景、使命、价值观这些公理上，生长出来的定理。</p>
<p>它们构成了这家公司的公理体系。</p>
<p>而这个体系，一定是完全自洽的。</p>
<p>什么叫完全自洽？</p>
<p>就是一家公司一旦有了完备的公理，其实就不需要老板来做决定了。</p>
<p>因为公理能推导出所有的定理。</p>
<p>不管公司以后会怎么发展，会遇到什么情况，只要有公理存在，就会演绎出一套能够解决问题的新的法则（定理）。</p>
<p>而当你发现你的公司每天都需要老板来做决定，或者你的规章制度、工作流程、决策行为和你的愿景、使命、价值观不符。</p>
<p>通常是因为公理还不完备，或者你的推导过程出现了问题。</p>
<p>这个时候你就需要修修补补，将你公司的公理体系一步步搭建起来。</p>
<p>我曾跟小伙伴说：</p>
<blockquote>
<p>我在公司只做三件事：设置责权利，捍卫价值观，和做一只安静的内容奶牛。</p>
<p>关于责权利法则，我们只有一条公理：创造最大价值的人，获得最大的收益。</p>
<p>所有的制度安排，都是我用我有限的智商，根据这条公理，推演出的定理。</p>
<p>任何制度安排（定理），如果违背了唯一的公理，那一定是我的智商不够用导致的。</p>
<p>我会为我的智商道歉，然后坚定地修改制度安排（定理）。</p>
<p>如果我拒不改正，或者对公理有动摇，请毅然决然地离开我。那个我，不值得你们跟随。</p>
<p>我们因为有相同的公理体系，而彼此成就。</p>
</blockquote>
<p>公理没有对错，不需要被证明，公理是一种选择，是一种共识，是一种基准原则。</p>
<p>制定不同的公理，就会得到完全不同的公理体系，也就会得到完全不同的结果。</p>
<h2 id="数学思维四-数字的方向性">数学思维四：数字的方向性</h2>
<p>第四种数学思维，源自于代数，叫做数字的方向性。</p>
<p>我们学代数，最开始学的是自然数，包括0和正整数：0，1，2，3，4，5……</p>
<p>然后是整数，包括自然数和负整数：……-3，-2，-1，0，1，2，3……</p>
<p>然后是有理数，包括整数和分数。</p>
<p>在学习分数之前，数字在我们的认知中，是离散的，是一个一个的点。</p>
<p>而有了分数，数字就开始变得连续了。</p>
<p>这就像在生活中，一开始你看事情，看的是对和错，大和小。</p>
<p>而慢慢地，你认识到世界其实并没有这么简单，你看事情开始有了灰度。</p>
<p>有理数之后，我们又学了无理数。</p>
<p>无理数，就是无限不循环小数，比如π。</p>
<p>任何一个有理数，都可以由两个数相除而得来。</p>
<p>但是无理数是无限不循环的小数，你找不到任何规律。</p>
<p>这会让你认识到，在这个世界上，有些事情就是复杂到无法有规律的。</p>
<p>π就是π，根号就是根号，它就是很复杂，你不要试图用一个简单粗暴的方式来定义它。</p>
<p>你要承认它的客观存在，承认这个世界的复杂性。</p>
<p>你看，我们不断深入学习各种数，其实就是在一步一步地理解世界的复杂。</p>
<p>再往复杂里说，数这个东西，除了大小，其实还有一个非常重要的属性：方向。</p>
<p>在数学上，我们把有方向的数字叫做向量。</p>
<p>数字，其实是有方向的。</p>
<p>这就像在公司里做事，两个人都很有能力，如果他们合作的时候，能力都能往一个方向使，形成合力，这是最好的结果。</p>
<p>而如果，他们的能力不能往一个方向使，反而互相牵制，那可能还不如完全交给其中一个人来做。</p>
<p>还有一种情况，做同一件事情，有的人想往东走，有的人想往西走，有的人想往北走，而你并不知道哪个方向是正确的。</p>
<p>这时，你想要的，不是合力的大小，而是方向的相对正确性。</p>
<p>那你该怎么办呢？</p>
<p>你就让他们都去干这件事吧。</p>
<p>虽然大家的方向不同，会互相牵制，力的大小会有损耗。</p>
<p>但是最终事情的走向，会是那个相对正确的方向。</p>
<h2 id="数学思维五-全局最优和达成共赢">数学思维五：全局最优和达成共赢</h2>
<p>第五种数学思维，源自于博弈论，叫做全局最优和达成共赢。</p>
<p>什么是博弈论？</p>
<p>我们每天都要做很多很多大大小小的决策。</p>
<p>比如，我今天是喝咖啡，还是喝茶？</p>
<p>这就是一个决策。</p>
<p>但这个决策只跟我自己有关，并不会涉及到别人。</p>
<p>而在生活中，有一类决策，是需要涉及到别人的。</p>
<p>涉及到别人的决策逻辑，我们把它叫做博弈论。</p>
<p>比如，下围棋就是典型的博弈。</p>
<p>每走一步棋，我的所得就是你的所失，我的所失就是你的所得。</p>
<p>这是博弈论中典型的零和博弈。</p>
<p>在零和博弈中，你要一直明白，你要的是全局的最优解，而不是局部最优解。</p>
<p>什么意思？</p>
<p>下围棋的时候，不是在每一步上，你都要吃掉对方最多的子。</p>
<p>你要让终局所得最多，就要步步为营，讲究策略。</p>
<p>有时候让子是为了以退为进，始终记得，你是为了全局最优，而不是局部最优。</p>
<p>很多时候办公司也是一样，不要总想着每一件事情都必须一帆风顺，如果你想得到最好的结果，可能在一些关键步数上就要做些妥协。</p>
<p>除了零和博弈，还有一种博弈，叫做非零和博弈。</p>
<p>非零和博弈讲究共赢。</p>
<p>共赢的前提，是建立信任。</p>
<p>建立信任，特别不容易，但是这件事情在商业世界里非常重要。</p>
<p>那怎么才能建立信任呢？</p>
<p>我给你两个建议。</p>
<p>第一个建议是，你要找到那些能够建立信任的伙伴。</p>
<p>有些人，是永远都无法和他达成共赢的，这样的人你就要远离。</p>
<p>第二个建议是，你要主动释放信任。</p>
<p>你要先让别人知道你是值得信任的人，这样想要与你达成共赢的人，就会来找到你。</p>
<h2 id="总结">总结</h2>
<p>这里介绍了5种数学思维：从不确定性中找到确定性，用动态的眼光看问题，公理体系，数字的方向性，以及全局最优和达成共赢。</p>
<p>你不一定要会解大部分数学题，你不一定要背下来所有公式，你不一定要数学考试拿满分，但是你至少要训练自己的数学思维。</p>
<p>训练数学思维，是为了让自己拥有符合规律的思维方式。</p>
<p>孔子说：三十而立，四十而不惑，五十而知天命，六十而耳顺，七十而从心所欲不逾矩。</p>
<p>所谓的从心所欲不逾矩，不是说我要约束自己，让自己想做的事情不越出边界。</p>
<p>而是我因为拥有符合规律的思维方式，所以我做的事情根本就不会越出边界。</p>
<p>这，就是从心所欲的自由。</p>

        
        ]]>
      </description>
    </item>
    
    
    
    <item>
      <title>杨绛语录</title>
      <link>/cn/2022/08/07/yangjiang/</link>
      <pubDate>Sun, 07 Aug 2022 00:00:00 +0000</pubDate>
      <author>Tan Jay</author>
      <guid>/cn/2022/08/07/yangjiang/</guid>
      <description>
        <![CDATA[
        <h2 id="语录">语录</h2>
<p>杨绛先生<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>说：</p>
<blockquote>
<p>“我们曾如此渴望命运的波澜，到最后才发现：人生最曼妙的风景，竟是内心的淡定与从容。 我们曾如此期盼外界的认可，到最后才发现：世界是自己的，与他人毫无关系。”</p>
</blockquote>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>公众号：<em>《特别关注》</em> 。<a href="https://mp.weixin.qq.com/s/Dz8nUlZR1ufNnvHfWyED2w">一个人内心越来越强大的3个迹象</a>&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>

        
        ]]>
      </description>
    </item>
    
    
    
    <item>
      <title>推文</title>
      <link>/cn/2022/08/02/webpages/</link>
      <pubDate>Tue, 02 Aug 2022 00:00:00 +0000</pubDate>
      <author>Tan Jay</author>
      <guid>/cn/2022/08/02/webpages/</guid>
      <description>
        <![CDATA[
        <h2 id="一些有用的网文">一些有用的网文</h2>
<h3 id="关于科研">关于科研</h3>
<ol>
<li><a href="https://mp.weixin.qq.com/s/-QVGsP87ap4tR6qsUts0IA">小编常用的科研网站</a></li>
<li><a href="https://mp.weixin.qq.com/s/-IKX-opthHcSlZNHilLL1A">推荐3个英语论文写作神器</a></li>
<li><a href="https://mp.weixin.qq.com/s/_Jh9BO6jyt6AbdHjwmDhOw">极大提高效率：论文写作工具杂谈(黄海广)</a></li>
<li><a href="https://mp.weixin.qq.com/s/tnUQZHiWUYCL7JVPeLvDRg">如何进行文献阅读</a></li>
<li><a href="https://mp.weixin.qq.com/s/1lcexdg8vmBQ3d0iYtm55Q">超级好用的查文献小插件</a></li>
</ol>
<h3 id="关于兴趣">关于兴趣</h3>
<ol>
<li><a href="https://cosx.org/archives/">统计之都·谢益辉</a></li>
<li><a href="https://mp.weixin.qq.com/s/BoIWAa70kmWNumu0BgiNsw">2022年R语言新书</a></li>
<li>RMarkdown制作beamer幻灯片
<ul>
<li><a href="https://cosx.org/2022/08/beamer-not-down/">网页教程</a></li>
<li><a href="http://github.com/eddelbuettel/binb">仓库地址</a></li>
</ul>
</li>
<li><a href="https://mp.weixin.qq.com/s/buabfqmHiV2LaXTw4B1kFw">黄海广博士机器学习之路</a></li>
<li><a href="https://mp.weixin.qq.com/s/1eirWJmar6PUpDCpJVPS_Q">黄海广的机器学习课程课件合集下载</a></li>
<li><a href="https://mp.weixin.qq.com/s/tfqPLHwiuOGTqRya2_3Ysg">黄海广公众号经典文章专辑</a></li>
<li><a href="https://mp.weixin.qq.com/s/FNcvzXPGv08ANSDqBQ1xGg">斯坦福大学CS229数学基础(线性代数、概率论)中文翻译版pdf</a></li>
<li><a href="https://mp.weixin.qq.com/s/08m8RQFcc2634baPX1mMtw">吴恩达积极学习新课</a></li>
<li><a href="https://mp.weixin.qq.com/s/Isas2fIVs6cxvEVRjPj62g">50个最佳机器学习公共数据集</a></li>
<li><a href="https://mp.weixin.qq.com/s/qmk2ATh6Ob1xAwPzxOlBWg">AI基础：走入深度学习</a></li>
<li><a href="https://www.icourse163.org/course/0818BIT059-1207432808?utm_campaign=share&amp;utm_medium=androidShare&amp;utm_source=">无人驾驶(慕课)</a></li>
</ol>
<h2 id="一些有趣的网文">一些有趣的网文</h2>
<h3 id="关于博客">关于博客</h3>
<ol>
<li><a href="https://yufree.cn/cn/2018/03/24/blogdown-rss/">blogdown的rss阅读器</a></li>
<li><a href="https://t.yihui.org">谢益辉推特</a></li>
<li><a href="https://zll-blog.netlify.app">庄闪闪博客</a></li>
<li><a href="https://github.com/fengdu78">黄海广Github</a></li>
</ol>
<h3 id="关于生活">关于生活</h3>
<ol>
<li><a href="https://mp.weixin.qq.com/s/nbjzSV7Nr568i6HV5drt1A">硬核科普，拒绝失眠</a></li>
<li><a href="https://mp.weixin.qq.com/s/MxSGziJOOtewL9c33hMaYQ">杨绛送给年轻人的7句话(人民日报)</a></li>
<li><a href="https://mp.weixin.qq.com/s/Dz8nUlZR1ufNnvHfWyED2w">内心强大的3个迹象</a></li>
<li><a href="https://mp.weixin.qq.com/s/cFBkeYHwahUm9lpPWwdU5Q">费曼：诞生天才的土壤是自由与兴趣</a></li>
<li><a href="https://mp.weixin.qq.com/s/qzi-iirrLKEumvvNGKe2Sg">刘润对谈吴军：每个人都一定要有数学思维</a></li>
<li><a href="https://mp.weixin.qq.com/s/N29_KR6XvTn4vIiPoqwz-A">你适合读博吗</a></li>
</ol>

        
        ]]>
      </description>
    </item>
    
    
    
    <item>
      <title>论文英语</title>
      <link>/cn/2022/07/26/paper_skill/</link>
      <pubDate>Tue, 26 Jul 2022 00:00:00 +0000</pubDate>
      <author>Tan Jay</author>
      <guid>/cn/2022/07/26/paper_skill/</guid>
      <description>
        <![CDATA[
        <h2 id="原则">原则</h2>
<ol>
<li>公式简洁</li>
<li>突出亮点（人无你有）</li>
</ol>
<h2 id="摘要">摘要</h2>
<h3 id="提出问题">提出问题</h3>
<ol>
<li>The ** is a ** problem.</li>
<li>It aims to do sth.</li>
<li>Aim to do sth</li>
<li>** has been widely used in many problems, but there are few relevant studies on **.</li>
</ol>
<h3 id="传统方法">传统方法</h3>
<ol>
<li>Traditional methods have difficulty ensuring sth when **.</li>
<li>Since (reason).<br>
It makes the method prone to miss the optimal solution, resulting in **.</li>
<li>**, leading to ** with low accuracy.</li>
<li>**, leading to the failure of sth.</li>
<li>Although, these ** can solve the problems, but ** still cannot meet the requirements.</li>
</ol>
<h3 id="建议方法">建议方法</h3>
<ol>
<li>In this work, ** method based on ** and ** is proposed to solve the problem.</li>
<li>A novel strategy was introduced into ** to improve the capability by v-ing.</li>
<li>A new ** is proposed, which **, then **.</li>
<li>, which is very effective for solving **.</li>
<li>The technologies that have been successfully applied include **, ** and so on.</li>
<li>** is used to solve the problem in complex environment.</li>
<li>owing to its advantage of **, ** shows remarkable performance in solving **.</li>
<li>In this paper, ** is proposed to handle the problems.</li>
<li>The method can alleviate **.</li>
</ol>
<h3 id="数值试验">数值试验</h3>
<ol>
<li>The simulation experimental results in ** show that the new method can ** and its performance is **.</li>
<li>The comparative experiments in these reports verify the effectiveness and reliability of these methods.</li>
<li>The superiority of the proposed method is experimentally verified.</li>
</ol>
<h2 id="行文">行文</h2>
<h3 id="句子">句子</h3>
<ol>
<li>is an indispensable part of</li>
<li>A series of algorithms</li>
<li>the number of nodes v-s</li>
<li>Sth have been proposed to solve this complex multi-constraint optimization problem</li>
<li>such as **, **, and **.</li>
<li>As sth increases and sth becomes adj.</li>
<li>The computational effort increases exponentially</li>
<li>in dealing with such problems</li>
<li>method used in paper</li>
<li>studied by researchers</li>
<li>proposed by sb</li>
<li>introduced by sb</li>
<li>inspired by sth</li>
<li>The research shows that **.</li>
<li>owing to its advantages</li>
<li>To improve sth, sb embeds sth into sth.</li>
<li>effects on</li>
<li>move toward</li>
<li>a hybrid strategy</li>
<li>the information is collected through ** to provide more ** for v-ing sth.</li>
<li>** is constructed</li>
<li>the information can be shared</li>
<li>The rest of the paper is explained as follows:</li>
<li>Section 1 describes **.</li>
<li>a summary is given in Section 5.</li>
</ol>
<h2 id="词藻">词藻</h2>
<h3 id="否定">否定</h3>
<ol>
<li>insufficient</li>
<li>low accuracy</li>
<li>premature</li>
<li>low timeliness</li>
</ol>
<h3 id="肯定">肯定</h3>
<ol>
<li>navel</li>
<li>effective and feasible</li>
<li>successfully</li>
<li>is superior to the other sth.</li>
<li>remarkable</li>
<li>elite</li>
<li>competitive</li>
<li>effectiveness and reliability</li>
<li>computational efficiency</li>
<li>recognition accuracy</li>
<li>promising</li>
</ol>
<h2 id="总结">总结</h2>

        
        ]]>
      </description>
    </item>
    
    
    
    <item>
      <title>诗</title>
      <link>/cn/2022/04/10/poetry/</link>
      <pubDate>Sun, 10 Apr 2022 00:00:00 +0000</pubDate>
      <author>Tan Jay</author>
      <guid>/cn/2022/04/10/poetry/</guid>
      <description>
        <![CDATA[
        <h3 id="heading"></h3>
<ol>
<li>桃李出深井，花艳惊上春。（李白）</li>
<li>人生在世不称意，明朝散发弄扁舟。（李白）</li>
<li>岑夫子，丹丘生，将进酒，杯莫停。（李白）</li>
<li>九曲黄河万里沙，浪淘风簸自天涯。<br>
如今直上银河去，同到牵牛织女家。（唐·刘禹锡）</li>
</ol>
<blockquote>
<p>九曲黄河从遥远的地方蜿蜒奔腾而来，一路裹挟着万里的黄沙。你从天边而来，如今好像要直飞上高空的银河，请你带上我扶摇直上，汇集到银河中去，一同到牛郎织女家做客吧。</p>
</blockquote>
<ol start="2">
<li>君看一叶舟，出没风波里。</li>
<li>草木蔓发，春山可望。</li>
<li>恨我生，手无缚鸡之力，徒劳说。</li>
<li>娇痴不怕人猜，和衣睡到人怀。</li>
<li>垆边人似月，皓腕凝霜雪。</li>
<li>仁则荣，不仁则厚。</li>
<li>此生此夜不长好，明月明年何处看。</li>
<li>治事必需通观全局，不可执一而论。</li>
<li>行百里者半九十。</li>
<li>一片花飞减却春，风飘万点正愁人。</li>
<li>凭君莫话封侯事，一将功成万骨枯。（曹松）</li>
<li>好话说破千言万语，不如干成实事一桩。（温家宝）</li>
<li>纵有疾风起，人生不言弃。</li>
<li>返景入深林，复照青苔上。</li>
<li>花飞蝴蝶乱，桑嫩野蚕生。（辛弃疾）</li>
<li>变化者，乃天地之自然。（葛洪）</li>
<li>其行己也恭<br>
其事上也敬<br>
其养民也惠<br>
其使民也义（孔子）</li>
<li>取次花丛懒回顾，半缘修道半缘君。（元稹）</li>
</ol>
<blockquote>
<p>曾经领略过苍茫的大海，就觉得别处的水相形见绌；<br>
曾经领略过巫山的云霭，就觉得别处的云黯然失色；<br>
即使身处万花丛中，我也懒于回头一望，<br>
这也许是因为修道，也许是因为你的缘故吧。</p>
</blockquote>

        
        ]]>
      </description>
    </item>
    
    
    
    <item>
      <title>同义替换</title>
      <link>/cn/2020/05/28/synonymous-substitution/</link>
      <pubDate>Thu, 28 May 2020 00:00:00 +0000</pubDate>
      <author>Tan Jay</author>
      <guid>/cn/2020/05/28/synonymous-substitution/</guid>
      <description>
        <![CDATA[
        <h2 id="同义替换">同义替换</h2>
<ul>
<li>
<p>ordeal = plight</p>
</li>
<li>
<p>obvious = apparent</p>
</li>
<li>
<p>to sequester oneself = to isolate oneself</p>
</li>
<li>
<p>bounce back = recover</p>
</li>
<li>
<p>irredeemable = hopeless</p>
</li>
<li>
<p>all but = almost</p>
</li>
<li>
<p>fraud 骗子<br>
= phoney<br>
= fraudulence<br>
= fake</p>
</li>
<li>
<p>cost the earth 代价惨重；花费一大笔钱，极其昂贵<br>
= cost a bomb<br>
= cost an arm and a leg</p>
</li>
<li>
<p>play on 利用（某人的弱点）<br>
= exploit</p>
</li>
<li>
<p>sate v. 满足（欲望）<br>
= satisfy</p>
</li>
<li>
<p>en vogue流行<br>
= in vogue</p>
</li>
<li>
<p>get hitched 结婚<br>
= to get married</p>
</li>
<li>
<p>purveyor 散布者；供应者<br>
= supply</p>
</li>
<li>
<p>protracted 延续很久的,长期的<br>
= prolonged</p>
</li>
<li>
<p>make it v. 继续生存，存活<br>
= survive</p>
</li>
<li>
<p>novice 新手，初学者<br>
= rookien</p>
</li>
<li>
<p>discernible 可察觉的，明显的<br>
= observable</p>
</li>
<li>
<p>entice v. 引诱<br>
entice/invite/persuade/convince sb. to do sth.<br>
attract sb. to do sth. / attract sb. to sth. 错误的事</p>
</li>
<li>
<p>lavish adj. 奢华的；大方的<br>
= luxurious</p>
</li>
<li>
<p>cachet n. 威望<br>
= prestige</p>
</li>
<li>
<p>affront n. 侮辱<br>
= insult</p>
</li>
<li>
<p>portrayal n.描绘，描述<br>
= depict</p>
</li>
<li>
<p>slump n. 低迷期，萧条期；锐减，猛跌 v. 锐减，猛跌<br>
= collapse</p>
</li>
<li>
<p>force n. 影响力，感染力；武力，力量<br>
= charisma</p>
</li>
</ul>

        
        ]]>
      </description>
    </item>
    
    
    
    <item>
      <title>情绪词语</title>
      <link>/cn/2020/05/14/emotional-words/</link>
      <pubDate>Thu, 14 May 2020 00:00:00 +0000</pubDate>
      <author>Tan Jay</author>
      <guid>/cn/2020/05/14/emotional-words/</guid>
      <description>
        <![CDATA[
        <ul>
<li>serene：淡定的 </li>
<li>complacent：自满的 </li>
<li>anixous: 担心的 </li>
<li>distracted：心烦意乱的 </li>
<li>pensive：沉思的 </li>
<li>bored：乏味的</li>
<li>happy: 快乐的 </li>
<li>trusting：轻易信赖别人的 </li>
<li>afraid：害怕的 </li>
<li>surprised：惊讶的 </li>
<li>sad：悲伤的 </li>
<li>disgusted：厌恶的</li>
<li>ecstatic：狂喜的 </li>
<li>admiring：钦佩的 </li>
<li>terrified：极度惊慌的 </li>
<li>amazed：吃惊的 </li>
<li>depressed：情绪低落的</li>
<li>loathing：憎恨的</li>
<li>annoyed：气恼的 </li>
<li>exhausted：精疲力竭的 </li>
<li>confused：困惑的 </li>
<li>paranoid：患妄想狂的 </li>
<li>smug：自鸣得意的 </li>
<li>nervous：紧张的</li>
<li>angry：生气的 </li>
<li>sleepy：欲睡的 </li>
<li>clueless：一窍不通的 </li>
<li>hysterical：情绪异常激动的 </li>
<li>confident：有自信的 </li>
<li>ashamed：耻辱的</li>
<li>furious：愤怒的 </li>
<li>embarassed：尴尬的 </li>
<li>overwhelmed：不知所措的 </li>
<li>hopeful：抱有希望的 </li>
<li>lonely：寂寞的 </li>
<li>lovestruck：热恋中的</li>
<li>jealous：嫉妒的 </li>
<li>mischievous：淘气的 </li>
<li>teary-eyed：眼含泪水的 </li>
<li>zoink：惊呼 </li>
<li>kawaii：可爱的</li>
<li>only adv.（用于动词前，表示结果令人遗憾或不受欢迎）愈加，只（会）</li>
<li>lean adj. 不景气的，萧条的；瘦的</li>
</ul>

        
        ]]>
      </description>
    </item>
    
    
    
    <item>
      <title>易混单词</title>
      <link>/cn/2020/04/19/confusing-word/</link>
      <pubDate>Sun, 19 Apr 2020 00:00:00 +0000</pubDate>
      <author>Tan Jay</author>
      <guid>/cn/2020/04/19/confusing-word/</guid>
      <description>
        <![CDATA[
        <h2 id="对比">对比</h2>
<ul>
<li>
<p>empire 帝国<br>
expire 到期的</p>
</li>
<li>
<p>outline 提纲</p>
<p>outlook 观点</p>
</li>
<li>
<p>fame 名誉
flame火焰</p>
</li>
<li>
<p>apotheosis 封神
algorithm 算法</p>
</li>
<li>
<p>bind 困境；捆
blind 盲的</p>
</li>
<li>
<p>grim 严肃的
grid 网格
rigid</p>
</li>
<li>
<p>boon 裨益
boom</p>
</li>
<li>
<p>entice 诱惑，诱使，引诱
ethics 伦理学
ethnic 民族的
ethical 道德的</p>
</li>
<li>
<p>battered adj. 受损的，（尤指）用坏了的；裹了面糊的
better</p>
</li>
<li>
<p>wring 拧
waring 警告</p>
</li>
<li>
<p>nigh adv.几乎；差不多；靠近
night</p>
</li>
<li>
<p>snake 蛇
snack 零食</p>
</li>
<li>
<p>temptation 诱惑
temper 脾气</p>
</li>
<li>
<p>bingev. 无节制地吃；n. 无节制的狂热行为
bingo</p>
</li>
<li>
<p>strife n. 冲突；纠纷；争吵
strike n. 罢工 v.（灾难）侵袭，（疾病）暴发；碰撞，击打</p>
</li>
<li>
<p>ethereal adj. 缥缈的，（尤指）超凡的
reclusive adj. 隐居的，遁世的
recluse（n. 隐士，隐居者）</p>
</li>
<li>
<p>plait v. 将（头发、绳子等）编成辫
braid n. 辫子；发辫 v. 编辫</p>
</li>
</ul>
<h2 id="词义辨析">词义辨析</h2>
<p><strong>perpetrator, criminal, offender</strong></p>
<pre><code>使用 perpetrator 来讨论罪犯时，语境中通常会出现具体的罪行。
criminal 则泛指犯下罪行，将要受到法律制裁的犯人。
offender 可以指代任何违反法律的人，即“违法者”。
offender 并不一定会被判为“罪犯”，也并不一定会受到法律的制裁。
</code></pre>
<p><strong>extort, blackmail</strong></p>
<pre><code>extort 和 blackmail 都可以表示“敲诈，勒索”。
blackmail 强调是以公开具有破坏性的信息的方式来威胁他人，
extort 更偏向于使用暴力威胁，或者是在双方权力悬殊的情况下进行威胁勒索。
blackmail 可以视为 extort 的其中一种方式。
</code></pre>
<p><strong>disinformation, misinformation</strong></p>
<pre><code>这两个词含义非常接近，但在一些英英词典中，
disinformation 更强调消息传播者的恶意和别有用心，
misinformation 更客观一些，往往指消息的误传、误报（可能是无意的）。
</code></pre>
<p><strong>lone, alone, lonely</strong></p>
<pre><code>lone 和 alone 都表示“独自的”，但两者在句子中出现的位置不同，大部分情况下不能互换。
lone 只能作定语放在名词前面（a lone wolf）
alone 常放在动词后面（The wolf lives alone）。
lonely 表示“孤单的，寂寞的”，和 lone, alone 的含义有一些差异。
</code></pre>
<p><strong>protracted,prolonged</strong></p>
<pre><code>protracted 和 prolonged 均表示“拖延的，持久的”
protracted 带有贬义
prolonged 的意义则更为中性客观。
</code></pre>
<h2 id="近义词">近义词</h2>
<p><strong>unverified</strong>
&ndash; adj. 未经验证的
&ndash; 近义词：unconfirmed, unsubstantiated
&ndash; 相关词汇：unauthorized（未经许可的，未经批准的）</p>
<p><strong>taciturn</strong>
&ndash; adj. 沉默寡言的
&ndash; 反义词：talkative (adj.)</p>

        
        ]]>
      </description>
    </item>
    
    
    
    <item>
      <title>英译成语</title>
      <link>/cn/2020/04/09/idiom/</link>
      <pubDate>Thu, 09 Apr 2020 00:00:00 +0000</pubDate>
      <author>Tan Jay</author>
      <guid>/cn/2020/04/09/idiom/</guid>
      <description>
        <![CDATA[
        <h3 id="形容词性">形容词性</h3>
<ul>
<li>full-fledged          		羽翼丰满的</li>
<li>critically-acclaimed  		备受好评的</li>
<li>sketchy 			粗略完成的；草草了事的</li>
<li>far-fetched  			牵强的，难以置信的</li>
<li>compelling  			引人入胜的，难以抗拒的</li>
<li>epic  				史诗一般的；壮丽的；巨大的；漫长而艰难的</li>
<li>awe-inspiring  		令人敬畏的；令人叹为观止的</li>
<li>neck and neck  		不相上下的，旗鼓相当的，势均力敌的</li>
<li>frugal and hard-working 	勤俭节约</li>
<li>sumptuous 			奢侈华丽的</li>
<li>prodigal  			浪费的</li>
<li>bittersweet 			苦乐参半的</li>
<li>dashing 			（男子）风度翩翩的；</li>
<li>taciturn 			沉默寡言的</li>
</ul>
<h3 id="名词性">名词性</h3>
<ul>
<li>double whammy 			双重打击</li>
<li>the bread-and-butter 		拳头产品
=marquee</li>
<li>grassroots 			平民百姓</li>
<li>pretension 			自命不凡；矫揉造作</li>
<li>silver lining			一线生机</li>
<li>behemoth 			超级公司；庞然大物，强大的事物</li>
<li>niche 				称心的位置；商机，市场定位</li>
</ul>
<h3 id="其他">其他</h3>
<ul>
<li>
<p>fresh starts 			重振旗鼓</p>
</li>
<li>
<p>bode ill.    			不容乐观</p>
</li>
<li>
<p>be caught flat-footed 		措手不及</p>
</li>
<li>
<p>dig in				固执不改</p>
</li>
<li>
<p>continue our relentless effort to 坚持不懈</p>
</li>
<li>
<p>step up to the plate		挺身而出</p>
</li>
<li>
<p>wile away 			打发时光</p>
</li>
<li>
<p>in a double bind 		进退维谷</p>
</li>
<li>
<p>be positioned to		准备好做…</p>
</li>
<li>
<p>fall foul of sb		与…产生分歧</p>
</li>
<li>
<p>come down to			一言以蔽之，简而言之</p>
</li>
<li>
<p>all the rage			风靡一时，十分流行</p>
</li>
<li>
<p>entrench v. 			使…根深蒂固；将…安置于壕沟</p>
</li>
<li>
<p>the best of intentions		一片好心</p>
</li>
<li>
<p>a wild-goose chase		白费力气，徒劳无功</p>
</li>
<li>
<p>nigh on indestructible		几乎坚不可摧</p>
</li>
<li>
<p>to widespread acclaim		广受好评</p>
</li>
<li>
<p>go wild with joy		欣喜若狂</p>
</li>
<li>
<p>dress up			盛装出席</p>
</li>
<li>
<p>carry a distinct echo		具有特别的共鸣</p>
</li>
<li>
<p>ahead of the pack		成功领先；出类拔萃</p>
<ul>
<li>pack（n. 一群人（尤指不受人喜欢的）；包裹）</li>
</ul>
</li>
<li>
<p>fall for sth. 			上当，对…信以为真 - fall for sb.			爱上某人</p>
</li>
<li>
<p>sb aren’t going down without a fight不战而退</p>
</li>
<li>
<p>start up again			重启</p>
</li>
<li>
<p>leaps and bounds		巨大的突破;迅速的进展</p>
</li>
<li>
<p>shelter in place		就地避难</p>
</li>
<li>
<p>bounce back			恢复，重振旗鼓</p>
</li>
<li>
<p>thumb sb&rsquo;s nose at		嗤之以鼻</p>
</li>
<li>
<p>go for good			永远消失，成为历史</p>
</li>
<li>
<p>strike a chord			引起共鸣</p>
</li>
<li>
<p>be worlds apart		截然不同，有着天壤之别</p>
</li>
<li>
<p>spur-of-the-moment 		一时冲动的，心血来潮的</p>
</li>
<li>
<p>one up sb 			高人（谁）一等</p>
</li>
<li>
<p>in a (new) light 		以（全新的）方式</p>
</li>
<li>
<p>in almost equal measure		几乎在同样的程度上，程度相当</p>
</li>
<li>
<p>It happens that…		说来凑巧</p>
</li>
<li>
<p>by happenstance		纯属偶然</p>
</li>
<li>
<p>put all our/one&rsquo;s eggs in one basket孤注一掷</p>
</li>
<li>
<p>seem meaningful and worthwhile	显得更有意义且妙趣横生</p>
</li>
<li>
<p>I catch myself thinking		不由自主想</p>
</li>
<li>
<p>more than a few		很多，相当多</p>
<ul>
<li>“more than + 形容词”在口语中起到加强语气和程度的作用。</li>
</ul>
</li>
<li>
<p>brace for			为（为困难或坏事）做准备</p>
</li>
<li>
<p>ride out			安然渡过（难关）</p>
</li>
<li>
<p>…have it all—except …		万事俱备 只欠东风</p>
</li>
<li>
<p>hunker down			（带有目的地）长期蹲守；蹲下，蹲坐</p>
</li>
<li>
<p>on the brink of 		处于（糟糕形势）的边缘</p>
</li>
</ul>

        
        ]]>
      </description>
    </item>
    
    
  </channel>
</rss>
